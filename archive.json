{
  "magic": "E!vIA5L86J2I",
  "timestamp": "2026-03-01T01:28:01.475799+00:00",
  "repo": "ietf-wg-privacypass/draft-arc",
  "labels": [
    {
      "name": "bug",
      "description": "Something isn't working",
      "color": "d73a4a"
    },
    {
      "name": "documentation",
      "description": "Improvements or additions to documentation",
      "color": "0075ca"
    },
    {
      "name": "duplicate",
      "description": "This issue or pull request already exists",
      "color": "cfd3d7"
    },
    {
      "name": "enhancement",
      "description": "New feature or request",
      "color": "a2eeef"
    },
    {
      "name": "good first issue",
      "description": "Good for newcomers",
      "color": "7057ff"
    },
    {
      "name": "help wanted",
      "description": "Extra attention is needed",
      "color": "008672"
    },
    {
      "name": "invalid",
      "description": "This doesn't seem right",
      "color": "e4e669"
    },
    {
      "name": "question",
      "description": "Further information is requested",
      "color": "d876e3"
    },
    {
      "name": "wontfix",
      "description": "This will not be worked on",
      "color": "ffffff"
    },
    {
      "name": "ietf123",
      "description": "",
      "color": "b829be"
    }
  ],
  "issues": [
    {
      "number": 7,
      "id": "I_kwDONyB6uM6rFQ2R",
      "title": "Use ZKProof spec for generation of Schnorr proofs",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/7",
      "state": "CLOSED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, ARC defines and uses its own ZKP Schnorr compiler.\nTo reuse redundancy and reuse tooling across projects, it would be better to use the ZKProof spec defined here:\nhttps://mmaker.github.io/spfs/draft-orru-zkproof-sigma.html#name-ciphersuites\n\nHowever, adopting the ZKProof spec is blocking on it having a reference implementation and test vectors, which I filed an issue for here:\nhttps://github.com/mmaker/spfs/issues/1",
      "createdAt": "2025-02-22T00:36:06Z",
      "updatedAt": "2026-02-27T05:09:18Z",
      "closedAt": "2026-02-27T05:09:18Z",
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "@mmaker, it looks like this draft is still unpublished, so we can't use it yet (beyond the reference implementation and test vector issue that Cathie mentioned above). What is your plan to get this published and worked on in the IETF?",
          "createdAt": "2025-02-24T18:11:33Z",
          "updatedAt": "2025-02-24T18:11:33Z"
        },
        {
          "author": "mmaker",
          "authorAssociation": "NONE",
          "body": "@chris-wood  I'm happy to have it worked with the IETF and integrate your compiler into one that can be compatible also with other specs.\nCan you give me ~1week-10days to publish an implementation?\n",
          "createdAt": "2025-02-24T20:16:07Z",
          "updatedAt": "2025-02-24T20:17:37Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Sorry, let me rephrase: do you intend to submit this to the [datatracker](https://datatracker.ietf.org)? As it stands now, the specification _does not exist_, because it's not published on the dataracker. In order for us to use it, we need it to be published in the datatracker. Additionally, are you opposed to co-authors on that specification? (If not, I recommend @cathieyun join to help out!) It will progress faster through the IETF that way.\n\nAnd yeah, there's no rush for the implementation. We're not blocked by any of this. We can move to a separate ZKP compiler if and when it becomes available. Until then, we will continue using the one specified in our draft.",
          "createdAt": "2025-02-24T20:19:08Z",
          "updatedAt": "2025-02-24T20:28:12Z"
        },
        {
          "author": "mmaker",
          "authorAssociation": "NONE",
          "body": "I am happy to submit this to the datatracker. \nI am also happy to have co-authors: in fact, you and @cathieyun are already contributors with push access to the repository.\n\nHowever, this is also the first ietf spec I write, so please consider that if I don't do something it's just that I was not aware of the policy! \n(For instance, I thought it'd be added to the data tracker **after** sharing it with the cfrg, and to do so i needed to make a good case with other working groups and write an implementation that suits them.)",
          "createdAt": "2025-02-25T05:39:38Z",
          "updatedAt": "2025-02-25T05:39:50Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "@mmaker understood, and no worries. You can (and should) submit to the datatracker frequently and often! This is just the place where IETF specifications live. IETF working groups and research groups require a draft to exist on the datatracker before it can be presented and considered for adoption. So, concretely, here's what I recommend you do:\n\n1. Update the co-authors to include whomever you like. (I think it's fine if you include me and Cathie -- our affiliation is included below).\n2. Submit to the datatracker.\n3. Share with CFRG and ask for time to present in Bangkok. \n\nThe reference implementation and test vectors can definitely come later, and that's OK. All that matters for now is that the draft be published so we can start \"the process.\" \n\nDoes that all make sense?\n\n------\n\nHere's the affiliation:\n\n```\nauthor:\n -\n    ins: C. Yun\n    name: Cathie Yun\n    organization: Apple, Inc.\n    email: cathieyun@gmail.com\n -\n    ins: C. A. Wood\n    name: Christopher A. Wood\n    org: Apple, Inc.\n    email: caw@heapingbits.net\n```",
          "createdAt": "2025-02-25T11:01:25Z",
          "updatedAt": "2025-02-25T11:01:25Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Now that the sigma and fiat-shamir specs have been adopted by CFRG, I am working on moving ARC to use those specs. Preliminary PR (with some open action items) here: https://github.com/chris-wood/draft-arc/pull/37",
          "createdAt": "2025-09-14T05:22:59Z",
          "updatedAt": "2025-09-14T05:22:59Z"
        }
      ]
    },
    {
      "number": 8,
      "id": "I_kwDONyB6uM6rFSQW",
      "title": "Define ARC protocol over a generic MAC protocol",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/8",
      "state": "OPEN",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, the ARC protocol is defined in relation to the CMZ14 MAC_GGM protocol. To more clearly illustrate which parts of the protocol are specific to ARC, and which can be generic over any MAC, we should define the ARC protocol over a generic MAC protocol, and then specify that MAC as CMZ14 MAC_GGM in a following section. \n\nThis will make it easier to later introduce different MAC backends, which have different tradeoffs (eg BBS MAC, muCMZ MAC, etc) without changing the protocol itself. \n\nThe initial change (defining the ARC protocol over a generic MAC, and defining CMZ14 MAC_GGM in a different section) will not change the functionality (test vectors will not be affected, for example) and is primarily editorial.",
      "createdAt": "2025-02-22T00:42:00Z",
      "updatedAt": "2025-10-30T18:57:36Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Related work on unifying MAC constructions for anonymous credentials:\nhttps://eprint.iacr.org/2025/1981",
          "createdAt": "2025-10-30T18:57:36Z",
          "updatedAt": "2025-10-30T18:57:36Z"
        }
      ]
    },
    {
      "number": 10,
      "id": "I_kwDONyB6uM6rbGWx",
      "title": "Statistical anonymity is not (yet) achieved",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/10",
      "state": "CLOSED",
      "author": "mmaker",
      "authorAssociation": "NONE",
      "assignees": [
        "cathieyun"
      ],
      "labels": [
        "ietf123"
      ],
      "body": "The specification currently writes:\n\n> The resulting request is therefore perfetly hiding, and independent from other requests from the same client. More details about this unlinkability property can be found in {{KVAC}} and {{REVISITING_KVAC}}.\n\nThis is not true. The  public parameters in your spec `X_0` is defined as\n```\n  X0 = x0 * G.GeneratorG() + x0Blinding * G.GeneratorH()\n```\nwhich is only computationally binding. \nAn adversary breaking DL could in theory find `x0` and `x0'`, both committing to `X0`, and use them to sign different credentials. \n\nThis is the reason why in {{REVISITING_KVAC}} I **don't** set `X0` in this way. \nIn order to achieve stronger privacy you need to commit to X0 differently. \n\n(Nitpick: I am also not sure how you can get more than statistical anonymity, from thm 5.10 you also need soundness of the user proofs.)",
      "createdAt": "2025-02-24T19:53:28Z",
      "updatedAt": "2025-06-23T20:54:39Z",
      "closedAt": "2025-06-23T20:54:39Z",
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "To clarify, the claim in the spec is that the *request* is perfectly hiding, meaning that multiple requests can't be linked to each other. This has nothing to do with the definition of the server keys, as the request doesn't use the server keys at all - only the response does. I'll make this clearer by renaming the section to \"Credential request unlinkability\" instead of \"Credential issuance unlinkability\", which may have led to the misunderstanding.",
          "createdAt": "2025-06-20T20:34:16Z",
          "updatedAt": "2025-06-20T20:34:16Z"
        }
      ]
    },
    {
      "number": 11,
      "id": "I_kwDONyB6uM6rbV1E",
      "title": "Improve issuance of credentials, from linear to constant communication",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/11",
      "state": "OPEN",
      "author": "mmaker",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "You can change the issuance protocol and have half communication on the server side and the client side.\nFor generic credentials, this is a constant vs linear improvement. \n\nReplace \n```\n  m1Enc = m1 * generatorG + r1 * generatorH\n  m2Enc = m2 * generatorG + r2 * generatorH\n```\n\nWith\n```\nmEnc = m1 * X1 + m2 * X2 + r * generatorG\n```\n\nas in {{REVISITING_KVAC}}",
      "createdAt": "2025-02-24T20:25:33Z",
      "updatedAt": "2025-08-29T18:02:25Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "We have considered changing the issuance protocol to the scheme in {{REVISITING_KVAC}}, but were concerned by the recency and lack of academic peer review of the {{REVISITING_KVAC}} paper. Furthermore, ARC only uses two attributes, so it would only save one group element, which is not very considerable in practice.\n\nHowever, the acceptance of the paper into the ACM CCS conference moves the needle toward the constant-size approach. I am happy to revisit this if there is interest from the community. ",
          "createdAt": "2025-08-27T06:15:19Z",
          "updatedAt": "2025-08-27T06:15:19Z"
        },
        {
          "author": "mmaker",
          "authorAssociation": "NONE",
          "body": "Thanks for your consideration! I was trying to say that the draft diverges from cryptographic literature, and that's not good.\n\n\nIn particular it introduces a weird security bug where the client will accept malformed credentials from people other than the issuer. In your efficiency count, I think you're forgetting about the proof size.\n\nChanges to the issuance protocol are really delicate, and I made mistakes for similar edge cases in the past too!\nYou don't have to use my paper, you can rely on issuance techniques from [CMZ14] and [PS16].\n",
          "createdAt": "2025-08-29T18:01:20Z",
          "updatedAt": "2025-08-29T18:02:25Z"
        }
      ]
    },
    {
      "number": 12,
      "id": "I_kwDONyB6uM6rb8z_",
      "title": "Reference implementation cleanup: seeded PRNGs for test vectors",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/12",
      "state": "OPEN",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "chris-wood"
      ],
      "labels": [
        "ietf123"
      ],
      "body": "Currently we get deterministic ZKP output by using an incrementing counter for blinding:\nhttps://github.com/chris-wood/draft-arc/blob/main/poc/zkp.sage#L62\n\nWe should move to a seeded PRNG instead, this is better practice. \n\n(Suggestion from Michele / @mmaker)",
      "createdAt": "2025-02-24T21:47:37Z",
      "updatedAt": "2026-02-27T05:13:37Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Updated the spec to use sigma, which is using a seeded PRNG:\nhttps://github.com/ietf-wg-privacypass/draft-arc/pull/37\n\nWill also update the POC to be in line with that spec change.",
          "createdAt": "2026-02-27T05:13:37Z",
          "updatedAt": "2026-02-27T05:13:37Z"
        }
      ]
    },
    {
      "number": 14,
      "id": "I_kwDONyB6uM6sL0dM",
      "title": "NotImplementedError",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/14",
      "state": "OPEN",
      "author": "mmaker",
      "authorAssociation": "NONE",
      "assignees": [
        "chris-wood"
      ],
      "labels": [
        "ietf123"
      ],
      "body": "Python has a specific exception for not-implemented errors, called \"[NotImplementedError](https://docs.python.org/3/library/exceptions.html#NotImplementedError)\". This should be preferred to raising a string object \"Not implemented\"",
      "createdAt": "2025-03-01T09:56:10Z",
      "updatedAt": "2025-06-13T20:07:56Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 16,
      "id": "I_kwDONyB6uM6sXSHS",
      "title": "MakePresentationState adds a nonce to the state",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/16",
      "state": "CLOSED",
      "author": "karulont",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "The code block at https://chris-wood.github.io/draft-arc/draft-yun-cfrg-arc.html#name-presentation-state that describes making the presentation state (`MakePresentationState`) also adds a single random nonce to the `presentationNonceSet`. It seems to me that it is not required, because `Present` will also pick a random nonce and add it to the set of used nonces.",
      "createdAt": "2025-03-03T16:55:06Z",
      "updatedAt": "2025-04-15T16:05:37Z",
      "closedAt": "2025-04-15T16:05:37Z",
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Ah that was a leftover of the previous approach of selecting nonces. Will update and remove that.",
          "createdAt": "2025-04-02T08:54:08Z",
          "updatedAt": "2025-04-02T08:54:08Z"
        }
      ]
    },
    {
      "number": 17,
      "id": "I_kwDONyB6uM6sXVn4",
      "title": "PrivacyPass: Section 8.1 improvements",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/17",
      "state": "CLOSED",
      "author": "karulont",
      "authorAssociation": "NONE",
      "assignees": [
        "chris-wood"
      ],
      "labels": [
        "ietf123"
      ],
      "body": "1. [Section 8.1](https://chris-wood.github.io/draft-arc/draft-yun-privacypass-arc.html#name-token-creation) could define what `challenge_digest` is.\n2. Notice the difference in description between `token_type` and `presentation_nonce`.\n```\n\"token_type\" is a 2-octet integer, in network byte order, equal to 0xC7D3.\n\"presentation_nonce\" is a 32-bit encoding of the nonce output from ARC.\n```\nOne defines the byte order, the other does not specify which \"32-bit encoding\". I suggest to use \"4-octet integer, in network byte order\"",
      "createdAt": "2025-03-03T16:59:57Z",
      "updatedAt": "2025-10-17T19:57:59Z",
      "closedAt": "2025-10-17T19:57:59Z",
      "comments": []
    },
    {
      "number": 18,
      "id": "I_kwDONyB6uM6sXYXW",
      "title": "PrivacyPass: Token Verification should mention checking the presentation tag.",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/18",
      "state": "CLOSED",
      "author": "karulont",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "[Section 8.2 Token Verification](https://chris-wood.github.io/draft-arc/draft-yun-privacypass-arc.html#section-8.2)\nShould mention that to avoid double spending, we need to check that the presentation tag has not been observed before.\nIt is mentioned in the ARC spec, but not in the privacy pass adoption.",
      "createdAt": "2025-03-03T17:04:55Z",
      "updatedAt": "2025-04-15T16:05:37Z",
      "closedAt": "2025-04-15T16:05:37Z",
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Added the same section to the privacy pass spec, thanks.",
          "createdAt": "2025-04-02T09:23:06Z",
          "updatedAt": "2025-04-02T09:23:06Z"
        }
      ]
    },
    {
      "number": 19,
      "id": "I_kwDONyB6uM6sXYrS",
      "title": "PrivacyPass: Section 9: the last link to Section 7.2 of [AUTHSCHEME] should instead be to: Section 6.2 of [ARCHITECTURE]",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/19",
      "state": "CLOSED",
      "author": "karulont",
      "authorAssociation": "NONE",
      "assignees": [
        "chris-wood"
      ],
      "labels": [
        "ietf123"
      ],
      "body": "[Section 9](https://chris-wood.github.io/draft-arc/draft-yun-privacypass-arc.html#name-security-considerations): the last link to Section 7.2 of [AUTHSCHEME] should instead be to: Section 6.2 of [ARCHITECTURE]",
      "createdAt": "2025-03-03T17:05:30Z",
      "updatedAt": "2025-10-16T14:40:03Z",
      "closedAt": "2025-10-16T14:40:03Z",
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "This should actually be linking to Section 7.2 of [ARC], as that is where the presentation nonce collisions are discussed. I will update the spec accordingly.",
          "createdAt": "2025-04-02T09:14:38Z",
          "updatedAt": "2025-04-02T09:14:38Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "This was fixed in 24a05782 -- closing.",
          "createdAt": "2025-10-16T14:40:03Z",
          "updatedAt": "2025-10-16T14:40:03Z"
        }
      ]
    },
    {
      "number": 20,
      "id": "I_kwDONyB6uM6s1EU7",
      "title": "PrivacyPass: Section 8.2 `request_context` and `presentation_context` are wrong",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/20",
      "state": "CLOSED",
      "author": "karulont",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "What happened is that #13 changed the `request_context` and `presentation_context` definitions, but it forgot to update them in Section 8.2: Token Verification.",
      "createdAt": "2025-03-06T07:30:14Z",
      "updatedAt": "2025-04-15T16:05:38Z",
      "closedAt": "2025-04-15T16:05:38Z",
      "comments": []
    },
    {
      "number": 21,
      "id": "I_kwDONyB6uM6tbECF",
      "title": "Confusion between instances and objects",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/21",
      "state": "OPEN",
      "author": "mmaker",
      "authorAssociation": "NONE",
      "assignees": [
        "chris-wood"
      ],
      "labels": [
        "ietf123"
      ],
      "body": "It seems there's some confusion about class attributes and instance attributes. For instance, in \n\nhttps://github.com/chris-wood/draft-arc/blob/main/poc/groups.sage#L220\n\nattributes like order, identity, etc can be accessed without instantiating the class (and it shouldn't be instantiated!)\nSame goes for other groups.\n\n",
      "createdAt": "2025-03-11T08:10:03Z",
      "updatedAt": "2025-09-13T20:54:54Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "`groups.sage` is the standard code for EC groups used across many IETF drafts (same goes for many other common sage/py files in the poc). So I believe we are using these files as intended.",
          "createdAt": "2025-09-13T20:54:54Z",
          "updatedAt": "2025-09-13T20:54:54Z"
        }
      ]
    },
    {
      "number": 22,
      "id": "I_kwDONyB6uM6t59an",
      "title": "PrivacyPass: 7.2. Issuer-to-Client Request: title should say \"Response\"",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/22",
      "state": "CLOSED",
      "author": "karulont",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "To better align with [existing docs](https://www.rfc-editor.org/rfc/rfc9578.html#name-issuer-to-client-response-2): the title should be \"Issuer-to-Client Response\"",
      "createdAt": "2025-03-13T15:53:20Z",
      "updatedAt": "2025-04-15T16:05:38Z",
      "closedAt": "2025-04-15T16:05:38Z",
      "comments": []
    },
    {
      "number": 23,
      "id": "I_kwDONyB6uM6uluWU",
      "title": "PrivacyPass: pointless renaming",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/23",
      "state": "CLOSED",
      "author": "karulont",
      "authorAssociation": "NONE",
      "assignees": [
        "chris-wood"
      ],
      "labels": [
        "ietf123"
      ],
      "body": "There are instances of things in the ARC privacypass proposal that rename things slightly when compared to the rest of the privacy pass documents. This increases friction for implementations which want to support multiple token types.\n\nConcrete examples where the previous term is replaced with a new slightly different name, but without changing the meaning.\n`token_key_id` -> `issuer_key_id`\n`truncated_token_key_id` -> `truncated_issuer_key_id`\n`application/private-token-request` -> `application/private-credential-request`\n`application/private-token-response` -> `application/private-credential-response`\n\nI do not believe that the new names add any extra value, but they might cause confusion(subjective opinion) and they will increase friction for implementations (objective opinion).",
      "createdAt": "2025-03-18T16:28:31Z",
      "updatedAt": "2025-10-17T22:46:02Z",
      "closedAt": "2025-10-17T22:46:02Z",
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "These are intentional, since ARC is about issuing _credentials_ and not _tokens_. I think we'll keep these as-is.",
          "createdAt": "2025-04-01T15:40:30Z",
          "updatedAt": "2025-04-01T15:40:30Z"
        },
        {
          "author": "karulont",
          "authorAssociation": "NONE",
          "body": "I see no benefit to renaming media types.\nIssuer who supports multiple token types, should parse the first 2 bytes of `TokenRequest` to figure out the token type.\n\nIn my opinion if you send a type called: `TokenRequest`, the media type should be `application-private-token-request`.\n\nAnyway, if you think that renaming the media type is appropriate, I have 2 followups:\n1. Why not rename \"TokenRequest\" / \"TokenResponse\"?\n2. You need to add the new media types to the [IANA MediaTypes registry](https://www.iana.org/assignments/media-types/media-types.xhtml).",
          "createdAt": "2025-04-01T21:42:40Z",
          "updatedAt": "2025-04-01T21:42:40Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Again, the thing being requested is _not_ a token, it's a credential. TokenRequest simply isn't precise.\n\nI'll reopen this to track the structure renaming and registry updates. Those should have been done.",
          "createdAt": "2025-04-02T16:47:09Z",
          "updatedAt": "2025-04-02T16:47:09Z"
        }
      ]
    },
    {
      "number": 24,
      "id": "I_kwDONyB6uM6uqiLL",
      "title": "Commonize handling process of presentationContext and nonce",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/24",
      "state": "CLOSED",
      "author": "akakou",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "I notice that the presentationContext and nonce serve similar roles at the protocol level; \nhowever, they are incorporated differently. \n\nIn my opinion, it might be simpler to \n- define `generatorT = G.HashToGroup(presentationContext || nonce, \"Tag\")`, or to \n- set `tag = (credential.m1 + nonce + HashToScalar(presentationContext))^(-1) * generatorT` instead. \n\nbut I have no confidence...Is it correct? ",
      "createdAt": "2025-03-19T04:03:23Z",
      "updatedAt": "2025-04-13T09:25:18Z",
      "closedAt": "2025-04-12T04:01:32Z",
      "comments": [
        {
          "author": "akakou",
          "authorAssociation": "NONE",
          "body": "I like the first approach because it can minimize the complexity of handling secret keys. Moreover, it may be better for compatibility with secure hardware[1, 2], similar to a rate limiter with secure hardware storage. Also, it might to be possible to eliminate the q-SDH assumption in the former case.\n\n[1] https://www.ndss-symposium.org/wp-content/uploads/2024-445-paper.pdf\n[2] https://github.com/akakou/scrappy/wiki/Scrappy-Extension-for-Counter-based-Rate%E2%80%90Limiting",
          "createdAt": "2025-03-19T04:04:47Z",
          "updatedAt": "2025-03-30T07:30:11Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks for your questions. I responded in the privacy pass mailing list thread here:\nhttps://mailarchive.ietf.org/arch/msg/privacy-pass/O7tXyXtcc9XKLk0UxLfDblJl9n0/\n\nHopefully that answers your questions. The first approach makes it much harder to hide the nonce in the future (without changing the tag construction), and the second approach can work but does not have any obvious advantage over our current ARC tag construction (and requires one more element in the presentation proof). If you have follow-up questions, feel free to re-open this issue or make a new issue. Thanks for your interest!",
          "createdAt": "2025-04-12T04:01:32Z",
          "updatedAt": "2025-04-12T04:01:32Z"
        },
        {
          "author": "akakou",
          "authorAssociation": "NONE",
          "body": "@cathieyun \n\nThank you for your clear response. I fully understand your explanation regarding the first answer\u2014it makes perfect sense. \nRegarding the second point, I apologize for any confusion in my previous message. I would like to clarify the unclear parts here.\n\n---\n\n## Explanation of `generatorT`\n\n> This might be true, but I haven't looked into this construction because if you remove the nonce, then the rate limiting capabilities of ARC are also removed, so this was not of interest to us. I would question the utility of a construction `tag = credential.m1 * generatorT` because it would be the same value for all presentations from one credential, so the presentations from one credential would be trivially linkable.\n\nI realize I did not explain the definition of `generatorT` in my earlier question. \nIn fact, this question is a continuation of [my previous discussion](https://mailarchive.ietf.org/arch/msg/privacy-pass/kxs6bErx252ENFD9YRnmzGCFhGE/). Please assume that `generatorT` is defined as:\n> generatorT = G.HashToGroup(presentationContext || nonce, \"Tag\")\n\nTo be more precise, the procedure I have in mind is:\n```\n1. generatorT = G.HashToGroup(presentationContext || nonce, \"Tag\") \n2. tag = credential.m1 * generatorT\n```\n\nIn this process, the nonce is used to compute the tag, which enables rate-limiting functionality.\n\n## Compatibility\n\n> I'm not sure what compatibility this refers to. To my understanding, ARC is compatible with the same extensions that BBS would be compatible with. For example, the per-verifier-linkability BBS spec (https://datatracker.ietf.org/doc/draft-irtf-cfrg-bbs-per-verifier-linkability/) could in theory use the rate limiting tag extension from ARC, and the other way around is true as well. \n\nI am under the assumption that you are interseted in compatibility for existing secure hardware (such as Trusted Platform Modules, TPMs), referring to the following [lines](https://chris-wood.github.io/draft-arc/draft-yun-cfrg-arc.html#name-alternatives-considered):\n> The BBS anonymous credential scheme, as detailed in [BBS] and its variants, is efficient and publicly verifiable, but requires pairings for verification. This is problematic for adoption because pairings are not supported as widely in software and **hardware** as non-pairing elliptic curves.\n\nMy concern is that most existing hardware may not support a calculation like `(credential.m1 + nonce)^(-1) * generatorT` because many devices do not offer functionality for such complex cryptographic operations handling  the secret key. \nOn the other hand, some hardware might support simpler multiplications, such as `credential.m1 * generatorT` which might make the procedure described above feasible. \n(I\u2019m not an expert on secure hardware, but I know TPMs can at least perform such multiplication.)",
          "createdAt": "2025-04-12T07:03:57Z",
          "updatedAt": "2025-04-13T09:25:17Z"
        },
        {
          "author": "akakou",
          "authorAssociation": "NONE",
          "body": "As you mentioned before, this scheme involves a clear trade-off as hardware compatibility & removing q-SDH assumption v.s. a simpler range-proof mechanism. To be honest, I'm not sure whether this discussion should be included in the draft. However, if you or the community are interested in it, it is possibility to be beneficial to include it as an extension point.",
          "createdAt": "2025-04-12T07:06:13Z",
          "updatedAt": "2025-04-12T08:45:25Z"
        },
        {
          "author": "akakou",
          "authorAssociation": "NONE",
          "body": "I would like to ask if this makes sense.\n\n",
          "createdAt": "2025-04-12T07:17:37Z",
          "updatedAt": "2025-04-12T07:17:37Z"
        }
      ]
    },
    {
      "number": 25,
      "id": "I_kwDONyB6uM6vPNi5",
      "title": "PrivacyPass: using TokenChallenge fields might be confusing",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/25",
      "state": "CLOSED",
      "author": "karulont",
      "authorAssociation": "NONE",
      "assignees": [
        "chris-wood"
      ],
      "labels": [
        "ietf123"
      ],
      "body": "To construct a request context one has to do:\n```\nrequest_context = concat(tokenChallenge.issuer_name,\n  tokenChallenge.origin_info,\n  tokenChallenge.credential_context,\n  issuer_key_id)\n```\n\nThen when one looks at:\n```\nstruct {\n    uint16_t token_type = 0xC7D3; /* Type ARC(P-384) */\n    opaque issuer_name<1..2^16-1>;\n    opaque redemption_context<0..32>;\n    opaque origin_info<0..2^16-1>;\n    opaque credential_context<0..32>;\n} TokenChallenge;\n```\n\nSo let's give a simple example:\nIssuer name is \"issuer.example.net\" & other fields are left empty.\n\nSo now should the `request_context` be\n```\n69 73 73 75 65 72 2e 65 78 61 6d 70 6c 65 2e 6e 65 74 <token_key_id>\n```\nOr should the request context contain all the length prefixes?\n```\n00 12 69 73 73 75 65 72 2e 65 78 61 6d 70 6c 65 2e 6e 65 74 00 00 00 <token_key_id>\n```\nNote we begin with 2 bytes for issuer name length, and end with 3 bytes of zeros, 2 for origin_info length and 1 for credential_context length.\n\nI assume the right interpretation is the second one where each field in the token challenge is prefixed by a length.\nBut when writing an implementation it is easy to make a mistake and forgot to include the length prefix. The spec should clarify it.",
      "createdAt": "2025-03-22T04:07:58Z",
      "updatedAt": "2025-10-17T22:06:40Z",
      "closedAt": "2025-10-17T22:06:40Z",
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Agreed that this should be clarified, to explicitly call out that we are serializing with the length. \nFor the tokenChallenge, this should look like:\n```\n2 byte length + tokenChallenge.issuer_name,\n2 byte length + tokenChallenge.origin_info,\n1 byte length + tokenChallenge.credential_context\n```\nThe same applies for the presentation context:\n```\n2 byte length + tokenChallenge.issuer_name,\n2 byte length + tokenChallenge.origin_info,\n1 byte length + tokenChallenge.redemption_context\n```",
          "createdAt": "2025-08-29T00:30:26Z",
          "updatedAt": "2025-08-29T00:30:26Z"
        }
      ]
    },
    {
      "number": 28,
      "id": "I_kwDONyB6uM6yDBLF",
      "title": "Privacy pass spec: client should hold onto tokenChallenge",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/28",
      "state": "CLOSED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The client needs to hold onto their latest tokenChallenge, so that they have something to compare to when they get a new tokenChallenge - to see if the credential_context, origin_info, redemption_context, or issuer_name changed.\n\nFor example, if any of those fields except redemption_context change, they will need to fetch a new credential.\nIf the redemption_context changes, they will need to use the new redemption context for making presentations (and will have a new rate limit, which may be relevant if they ran out of their rate limit for the previous redemption context).",
      "createdAt": "2025-04-10T23:07:31Z",
      "updatedAt": "2025-04-15T16:05:38Z",
      "closedAt": "2025-04-15T16:05:38Z",
      "comments": []
    },
    {
      "number": 29,
      "id": "I_kwDONyB6uM6ypQJo",
      "title": "Privacy pass: Verifier needs to parse out presentation tag for rate limiting",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/29",
      "state": "CLOSED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "chris-wood"
      ],
      "labels": [
        "ietf123"
      ],
      "body": "The verifier needs to store `presentation.tag` for rate limiting, so it needs to be able to parse that out from the `presentation` opaque blob. There currently isn't an API for the verifier to explicitly access the tag.",
      "createdAt": "2025-04-15T17:40:50Z",
      "updatedAt": "2025-10-17T19:57:01Z",
      "closedAt": "2025-10-17T19:57:01Z",
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Alternatively, can update `VerifyPresentation` to output not only a bool, but also the tag. I like this, it's cleaner / reduces API functions, and forces the verifier to verify the presentation before getting the tag (no invalid tag storage!)",
          "createdAt": "2025-04-15T17:41:43Z",
          "updatedAt": "2025-04-15T17:41:43Z"
        }
      ]
    },
    {
      "number": 30,
      "id": "I_kwDONyB6uM60DAn4",
      "title": "ARC CFRG spec should include P256 test vectors",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/30",
      "state": "CLOSED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "cathieyun"
      ],
      "labels": [
        "ietf123"
      ],
      "body": "Since the CFRG spec says P256 and P384 are both supported, both ciphersuites should have test vectors. Currently there are only test vectors for P384.",
      "createdAt": "2025-04-25T17:59:54Z",
      "updatedAt": "2025-06-23T18:38:44Z",
      "closedAt": "2025-06-23T18:38:44Z",
      "comments": []
    },
    {
      "number": 36,
      "id": "I_kwDONyB6uM7LfACG",
      "title": "Call for adoption feedback",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/36",
      "state": "CLOSED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "RandomScalar() in 3.1 returns a non-zero element, but P-256 desc in 6.1 generates a scalar in [0, G.Order() - 1], i.e. includes zero. A zero for blinding factors or randomization scalars breaks the protocol.\n\nProver in 5.1.1.4 appends blinded_element in a loop over a linear_combination, but Verifier in 5.1.2.2 appends challenge_element once per constraint.\n\nSchnorr mismatches/verification bugs in 5.1: Prover appends multiple blinded_elements per constraint. Verifier appends one, so challenges won't match. Verify() also uses self.elements vs state.elements.\n",
      "createdAt": "2025-09-13T17:46:30Z",
      "updatedAt": "2026-02-27T05:09:18Z",
      "closedAt": "2026-02-27T05:09:18Z",
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "The RandomScalar() definitions were copied boilerplate from the OPRF spec (RFC 9497): https://datatracker.ietf.org/doc/rfc9497/\nSo, it turns out the definitions mismatch in the OPRF spec as well! I discussed with Sofia and she confirmed that the curve-specific description should be `[1, G.Order() - 1]` instead of `[0, G.Order() - 1]`, and that the poc and all other uses of RandomScalar expect to omit the zero scalar. She mentioned that the OPRF spec authors could send an errata to fix that.\nI will also fix that typo in the ARC and ATHM drafts.\n\nAs for the Schnorr compiler mismatches - we are actually in the process of moving over to use the Sigma Protocols spec (which has been adopted by CFRG): https://datatracker.ietf.org/doc/draft-irtf-cfrg-sigma-protocols/, as I promised in the IETF123 meeting. So I appreciate the catches, but I will actually just remove the entire Schnorr compiler section soon (https://github.com/chris-wood/draft-arc/pull/37), so these will no longer be relevant.",
          "createdAt": "2025-09-17T05:33:25Z",
          "updatedAt": "2025-09-17T05:33:25Z"
        }
      ]
    },
    {
      "number": 46,
      "id": "I_kwDONyB6uM7U6h0o",
      "title": "Privacy Pass adoption - spec renames",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/46",
      "state": "CLOSED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Following guidance for specs after they have been adopted by working groups:\nhttps://datatracker.ietf.org/doc/rfc7221/\n\nWe should rename the specs accordingly:\n`draft-yun-privacypass-arc` -> `draft-ietf-privacypass-arc`\n`draft-yun-privacypass-crypto-arc` -> `draft-ietf-privacypass-crypto-arc`\nin order to reflect the fact that they have been adopted by the privacy pass working group.\n\n(I'm also open to better names than `privacypass-crypto` for the spec that was formerly the `cfrg` spec).",
      "createdAt": "2025-10-30T19:00:14Z",
      "updatedAt": "2026-02-27T05:11:58Z",
      "closedAt": "2026-02-27T05:11:58Z",
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Closed by https://github.com/ietf-wg-privacypass/draft-arc/pull/54",
          "createdAt": "2026-02-27T05:11:58Z",
          "updatedAt": "2026-02-27T05:11:58Z"
        }
      ]
    },
    {
      "number": 47,
      "id": "I_kwDONyB6uM7ZQ-mC",
      "title": "Proposal: Range Proofs for Credential Validity Timestamps in ARC",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/47",
      "state": "CLOSED",
      "author": "mike-marcacci",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Firstly, thank you all for your incredible work on these specs.\n\n## Summary\n\nI'm building a privacy-preserving access control system for cloud services and have identified a need for zero-knowledge range proofs on credential validity timestamps (both `valid_from` and `valid_until`) within the ARC protocol. This would enable flexible credential expiration without revealing specific timestamps that could shrink anonymity sets.\n\n## Use Case\n\nMy architecture separates concerns across three layers:\n\n- **Client layer**: End-user software that holds credentials and payment methods\n- **Service layer**: Cloud services (search, AI inference, data sync) that must not know user identity\n- **Payment layer**: Issues credentials when users purchase access (e.g., \"$15 for one month of service\")\n\nThe design goal is that the service layer cannot correlate activity with the payment layer or between different requests.\n\n## Current Limitation\n\nARC provides excellent unlinkability properties for rate-limited access, but credential validity must currently be managed by encoding validity in the request context:\n\n```\nrequestContext = \"payment-session:xyz:expires:2025-01\"\n```\n\nThis value is available in the clear with each presentation, and is therefore at a high risk of leaking correlating information. To ensure a sufficiently large anonymity set, credential expirations must align to fixed calendar boundaries.\n\nIn smaller scale services and whenever the cost of a credential is high (paying $20 as opposed to simply passing a captcha) the number of credentials will be small, and the fixed interval must be wide to ensure adequate privacy.\n\nAdopting a large \"common epoch\" like calendar months has many consequences:\n- Proration is required for new mid-month users.\n- New credentials for immediate use are constrained to the number of days remaining this month.\n- It's impossible to reliably offer credentials with shorter lifespans (1 week, etc).\n- A single limit cannot span multiple months.\n\nIn deployments that can support a small \"common epoch\" like days without privacy concerns, the use of such small windows imposes its own constraints. Breaking a subscription for \"3000 requests per month\" into 30 credentials supporting \"100 requests per day\" meaningfully changes the supported for irregular usage patterns.\n\n## Desired Capability\n\nI'd like the client to be able to prove:\n\n```\nvalid_from <= current_time <= valid_until\n```\n\nWithout revealing the actual values of `valid_from` or `valid_until`.\n\nThis would require:\n\n1. **Credential attributes for timestamps**: The credential would include `valid_from` and `valid_until` as hidden attributes (similar to how the balance is hidden in ACT)\n2. **Range proofs during presentation**: The client proves the current timestamp falls within the validity window using a zero-knowledge range proof\n3. **Unlinkability preservation**: Different credentials with different validity windows remain indistinguishable to the verifier\n\n## Technical Considerations\n\n### Timestamp representation\n\nTimestamps could be represented as Unix epoch seconds (or milliseconds), fitting within the scalar field. A 64-bit timestamp provides sufficient range and precision.\n\n### Range proof construction\n\nThe existing open issue mentions Bulletproofs for hiding the nonce:\n\n> [[OPEN ISSUE: hide the nonce and replace the tag proof with a range proof built from something like Bulletproofs.]]\n\nSimilar techniques could apply to timestamp bounds. The client would prove:\n- `current_time - valid_from >= 0` (credential has started)\n- `valid_until - current_time >= 0` (credential hasn't expired)\n\n### Clock synchronization\n\nPractical deployments would need to handle clock skew between client and server. The server could:\n- Accept a small tolerance (e.g., \u00b160 seconds)\n\n## Benefits\n\n1. **Flexible validity periods**: Users can purchase arbitrary durations without aligning to calendar boundaries\n2. **Seamless renewal**: Users can purchase overlapping credentials without complexity\n3. **Preserved anonymity**: No timestamps revealed that could fingerprint users\n4. **Simplified tag management**: Server can still use course epochs for tag storage cleanup, but credential validity is decoupled from these operational concerns\n\n## Questions for the Working Group\n\n1. Is this functionality in scope for ARC, or would it be better suited as a separate extension?\n2. Are there performance concerns with adding two range proofs (for both bounds) to each presentation?\n3. How should clock synchronization be handled between client and server?\n4. Are there existing constructions or implementations that could be referenced for this? \n5. Would this interact with the existing open issue around hiding the nonce with Bulletproofs, or are these orthogonal concerns?\n\n(Note: A related discussion exists at\u00a0[https://github.com/SamuelSchlesinger/draft-act/issues/7](https://github.com/SamuelSchlesinger/draft-act/issues/7))\n## More About My Use Case\n\nI'm designing a commercial cloud service where privacy is a core feature. Users pay for access through a separate payment layer, then access services without those services knowing their identity. The current ARC design works adequately for my immediate needs using monthly epochs, but timestamp range proofs would significantly improve flexibility and user experience.\n\nI know that this isn't the primary use-case of the Privacy Pass project, but it appears deeply compatible in its goals and implementation. Using Privacy Pass as a privacy-preserving \"proof of purchase\" mechanism is a very interesting general use-case.\n\nI'm happy to provide additional details about the use case or discuss implementation considerations. While my cryptographic knowledge is fairly rudimentary, I'm willing to contribute wherever I can be helpful, particularly to testing or implementation work.\n",
      "createdAt": "2025-11-20T02:08:13Z",
      "updatedAt": "2026-02-26T17:55:03Z",
      "closedAt": "2026-01-08T05:17:33Z",
      "comments": [
        {
          "author": "mike-marcacci",
          "authorAssociation": "NONE",
          "body": "Hi team! I just wanted to follow up about this and confirm that GitHub Issues is an appropriate place for its discussion. I'm happy to send an email to the IETF group instead, but this felt more collaborative.\n\nGiven that in the first iteration of my project I play the roles of both issuer and verifier, I don't really _need_ my implementation to follow any standard. However, my needs seem quite generalized and highly congruent with the existing goals of the Privacy Pass project. I'd love to know if this feels well aligned or categorically out of scope for ARC.",
          "createdAt": "2025-12-03T18:25:57Z",
          "updatedAt": "2025-12-03T18:25:57Z"
        },
        {
          "author": "mike-marcacci",
          "authorAssociation": "NONE",
          "body": "While working on #48 I found some flaws in my understanding of ARC, and I no longer find this necessary. More specifically, my use-case requires `presentationLimit` be set during issuance, which is very intentionally not the flow in ARC. I'm going to close this.\n\nTimestamp validity ranges might be valuable for other use-cases. If they're to be defined adjacent the `presentationContext` rather than the issuance `requestContext`, #48 provides excellent machinery to efficiently add them. But that's for a new issue.",
          "createdAt": "2026-01-08T05:17:33Z",
          "updatedAt": "2026-01-08T05:17:33Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Sorry for missing this issue until now! (I'll blame https://github.com/orgs/community/discussions/176383 for my inability to update my settings to get emailed about new issues/PRs... hoping that gets resolved, but in the meantime I will check manually more often!)\n\nIn case it's still helpful, here are some responses. I do still think your solution is workable, if you are willing to accept the complexity and performance overheads (which may be significant, depending on your timestamp granularity and some other considerations.)\n\n1. Is this functionality in scope for ARC, or would it be better suited as a separate extension?\nI think this would be better as a separate extension, due to the performance overhead - wouldn't want to make all ARC adopters have to incur that performance hit if they don't need fine-grained expiration bounds.\n\n2. Are there performance concerns with adding two range proofs (for both bounds) to each presentation?\nYes - depending on your granularity of timestamp, and how large of a range you will allow for each of these to be >= 0:\n`current_time - valid_from >= 0` (credential has started)\n`valid_until - current_time >= 0` (credential hasn't expired)\nBecause you can't just prove that they're >= 0... you have to proof that they are in some range `[0, n)` and the larger `n` is, the more expensive the range proof is.\n\n3. How should clock synchronization be handled between client and server?\nI don't actually see why this question is relevant - to my understanding, the current time would be sent in the clear, so the server can just see how much that differs from its own timestamp when it has received it, and if the gap is too large then it can choose to discard it.\n\n4. Are there existing constructions or implementations that could be referenced for this?\nNot that I'm aware of, but this could be a good questions for the IETF privacy pass group - they're a great source of knowledge :)\n\n5. Would this interact with the existing open issue around hiding the nonce with Bulletproofs, or are these orthogonal concerns?\nThese are orthogonal. The nonce hiding is a for rate limiting within the credential validity bounds, whereas you are discussing how to determine the credential validity bounds.\n\n> While working on https://github.com/chris-wood/draft-arc/pull/48 I found some flaws in my understanding of ARC, and I no longer find this necessary. More specifically, my use-case requires presentationLimit be set during issuance, which is very intentionally not the flow in ARC. I'm going to close this.\n\nI'm curious what you mean by \"presentationLimit must be set during issuance\"? Because you can set the expected rate limit in the tokenChallenge (which is bound to the credential) in the `redemption_context` field. Then during presentation, you have to encode `redemption_context` in the `presentation_context`, which is sent in the clear and bound to the presentation:\n```\npresentation_context = concat(\n  encode(2, len(challenge.issuer_name)),\n  challenge.issuer_name,\n  encode(2, len(challenge.origin_info)),\n  challenge.origin_info,\n  encode(2, len(challenge.redemption_context)),\n  challenge.redemption_context,\n  issuer_key_id)\n```\nThe verifier could check that the value set in redemption_context matches the presentation limit it expects (or just set presentation limit to that value). This forces the presentation_limit to be bound to the credential at the time of issuance.\n\nAlso if that's too complex, you can just hardcode a presentation limit for a given issuance/verification key.\n\nBoth of these approaches work if you don't expect there to be too many different presentation limits (eg a \"free\" vs \"paid\" tier). But if you expect every user to have a different presentation limit, for some reason, then these approaches which reveal the presentation limit at the time of presentation will not work, and you'd have to do something more complex which hides the presentation limit (possible, but yet another layer of complexity).",
          "createdAt": "2026-01-12T06:43:16Z",
          "updatedAt": "2026-01-12T06:43:16Z"
        },
        {
          "author": "mike-marcacci",
          "authorAssociation": "NONE",
          "body": "Thank you so much for your reply @cathieyun, and *my* apologies for such a delayed response (I somehow missed your message too).\n\nThanks also for answering these questions. A couple, I suppose, were more \"open\" questions inherently raised by the proposed feature (clock synchronization, etc).\n\nRE the scenario you proposed, I really hadn't considered that. Passing this value in the clear during presentation was something I was avoiding, but you're absolutely right that given few \"tiers\", they would each have sufficient anonymity sets to avoid this being an issue.\n\nMy focus has been on other components of this system over the past month, but I'm returning to this piece now.\n\nIs it helpful for me to share my evolving thoughts and experience as I work through this use case, or is it just noise?",
          "createdAt": "2026-02-26T17:55:02Z",
          "updatedAt": "2026-02-26T17:55:02Z"
        }
      ]
    },
    {
      "number": 49,
      "id": "I_kwDONyB6uM7i0Jy3",
      "title": "design: Simplify definition of u in MAC",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/49",
      "state": "OPEN",
      "author": "armfazh",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "During definition of MAC, the `u` element is chosen at random from the group.\n\n<img width=\"1981\" height=\"454\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2860ac6d-4be9-458d-b836-471575145a14\" />\n\n---\n\nIn the implementation, [the spec](https://datatracker.ietf.org/doc/html/draft-yun-privacypass-crypto-arc-00#name-credential-response) performs this step as:\n\n```python\n  b = G.RandomScalar()\n  U = b * generatorG\n```\n\nand then the parameter `b` appears in most of the [constraint equations](https://datatracker.ietf.org/doc/html/draft-yun-privacypass-crypto-arc-00#name-credentialresponse-proof-cr) to compute the issuer's proof.\n\nI suggested for analysis the following changes: \n\n1) Not to enforce `b` in the constraints because this is an ephemeral value. This can help reduce the number of linear constraints.\n\n2) Instead of perfoming a scalar multiplication for defining `u`, we can use a hash-to-group function as:\n\n```python\n  b = random_bytes(32)\n  U = G.HashToGroup(b)\n```\n\nIn practice, hashing to group is around 25% the cost of a scalar multiplication improving the execution time for issuers.\n\n",
      "createdAt": "2026-01-12T17:40:56Z",
      "updatedAt": "2026-01-12T20:41:25Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks Armando! This is a great catch.\n\nNote that we can do (1) and re-define the constraints to be in terms of `U` rather than `b`, without necessarily doing (2). But both are improvements worth doing.",
          "createdAt": "2026-01-12T20:41:25Z",
          "updatedAt": "2026-01-12T20:41:25Z"
        }
      ]
    },
    {
      "number": 56,
      "id": "I_kwDONyB6uM7rLlG-",
      "title": "Simplification of challenge composition",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/56",
      "state": "CLOSED",
      "author": "martinthomson",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Given that `Ne` is a constant, why are you encoding it for each element in [ComposeChallenge](https://ietf-wg-privacypass.github.io/draft-arc/draft-ietf-privacypass-arc-crypto.html#section-5.1.1.4-4)?  It seems like the I2OSP calls there can be dropped.",
      "createdAt": "2026-02-16T03:25:46Z",
      "updatedAt": "2026-02-27T05:19:20Z",
      "closedAt": "2026-02-27T05:19:20Z",
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "This is addressed by moving from our in-spec \"proof compiler\" to the Sigma Protocols / Fiat-Shamir specs. This migration happened for the spec in https://github.com/ietf-wg-privacypass/draft-arc/pull/37.",
          "createdAt": "2026-02-27T05:19:20Z",
          "updatedAt": "2026-02-27T05:19:20Z"
        }
      ]
    },
    {
      "number": 57,
      "id": "I_kwDONyB6uM7rLmWI",
      "title": "Formatting",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/57",
      "state": "OPEN",
      "author": "martinthomson",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "The number of code blocks in this document is high, which is understandable.  However, these blocks also include a bunch of extra text: preconditions, inputs, outputs, and so forth.  These end up being badly formatted, as code blocks don't get the benefit of wrapping and whatnot.  For instance, very few of the diagrams fit the 72 column width.\n\nConsider reformatting code blocks.",
      "createdAt": "2026-02-16T03:27:50Z",
      "updatedAt": "2026-02-16T03:27:50Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 58,
      "id": "I_kwDONyB6uM7rLnY3",
      "title": "Constrain: label or result?",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/58",
      "state": "CLOSED",
      "author": "martinthomson",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "https://datatracker.ietf.org/doc/html/draft-ietf-privacypass-arc-crypto-00#section-5.1.1.3 says:\n\n```python\ndef Constrain(label, linearCombination):\n  state.constraints.append((result, linearCombination))\n```\n\nThe rest of the definition uses \"result\", so I think that \"label\" is in error.",
      "createdAt": "2026-02-16T03:29:38Z",
      "updatedAt": "2026-02-27T05:20:10Z",
      "closedAt": "2026-02-27T05:20:10Z",
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "This is addressed by moving from our in-spec \"proof compiler\" to the Sigma Protocols / Fiat-Shamir specs. This migration happened for the spec in https://github.com/ietf-wg-privacypass/draft-arc/pull/37.",
          "createdAt": "2026-02-27T05:20:10Z",
          "updatedAt": "2026-02-27T05:20:10Z"
        }
      ]
    },
    {
      "number": 59,
      "id": "I_kwDONyB6uM7rLoSm",
      "title": "ComputeStatementAndWitnesses missing r argument",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/59",
      "state": "CLOSED",
      "author": "martinthomson",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Probably an error, because it is described, but the code is unclear.\n\nThe code also calls `allocate_scalars` and `allocateScalars` on consecutive lines.",
      "createdAt": "2026-02-16T03:31:24Z",
      "updatedAt": "2026-02-27T05:24:00Z",
      "closedAt": "2026-02-27T05:23:59Z",
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "This was addressed by the PR to incorporate the range proof into the actual presentation:\nhttps://github.com/ietf-wg-privacypass/draft-arc/pull/53\n\n(Will update the datatracker tag accordingly!)",
          "createdAt": "2026-02-27T05:24:00Z",
          "updatedAt": "2026-02-27T05:24:00Z"
        }
      ]
    },
    {
      "number": 60,
      "id": "I_kwDONyB6uM7rLo-A",
      "title": "Better range proof",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/60",
      "state": "CLOSED",
      "author": "martinthomson",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "The range proof does the typical 0..2^n proof that involves decomposition and proof of bit-ness.  This could be improved using the same techniques recently added in the VDAF spec.",
      "createdAt": "2026-02-16T03:32:44Z",
      "updatedAt": "2026-02-27T05:42:11Z",
      "closedAt": "2026-02-27T05:42:11Z",
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Just checking, are you referring to the range checks in the VDAF spec here?\nhttps://www.ietf.org/archive/id/draft-irtf-cfrg-vdaf-18.html#section-7.4.2-3\n\nThe range proof actually uses the same bit decomposition base selection tricks as the VDAF spec (not a coincidence, we have been in collaboration with the VDAF spec authors). So, it is not constrained to [0..2^n) ranges but can do proof of arbitrary ranges.\n\nFrom the VDAF spec:\n> All but the last of the weights are successive powers of two, as in the binary bit decomposition, and the last weight is chosen such that the sum of all weights is equal to max_measurement.\n\nThe only difference in ARC is that we are sorting the bases, so the non-power-of-two base is not at the end but rather in the sorted list. But this is just an implementation detail. ",
          "createdAt": "2026-02-27T05:42:11Z",
          "updatedAt": "2026-02-27T05:42:11Z"
        }
      ]
    },
    {
      "number": 61,
      "id": "I_kwDONyB6uM7rbSEu",
      "title": "What is LinearRelation?",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/61",
      "state": "OPEN",
      "author": "martinthomson",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "There is a `LinearRelation` type used in the range proof that doesn't have a definition.  The associated methods look like they might relate to the functions that `Prover` provides, but they take a different form.",
      "createdAt": "2026-02-16T22:22:04Z",
      "updatedAt": "2026-02-27T08:20:01Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "LinearRelation is defined in the Sigma Protocol spec here:\nhttps://github.com/mmaker/draft-irtf-cfrg-sigma-protocols/blob/main/draft-irtf-cfrg-sigma-protocols.md#statements-for-linear-relations\n\nIt is (now, as of https://github.com/ietf-wg-privacypass/draft-arc/pull/37) used in all the proof generation and verification functions to create the \"proof circuit\".",
          "createdAt": "2026-02-27T05:16:29Z",
          "updatedAt": "2026-02-27T05:16:29Z"
        },
        {
          "author": "martinthomson",
          "authorAssociation": "NONE",
          "body": "You probably should explicitly point to what you are using from that draft somewhere.  I see no references to LinearRelation except in code.  (And only one reference to the draft as a whole outside of some broken references in the code (`{{SIGMA}}`).",
          "createdAt": "2026-02-27T07:12:31Z",
          "updatedAt": "2026-02-27T07:12:31Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Ok, will re-open this issue and address it in a cleanup PR. Thanks for the callout.",
          "createdAt": "2026-02-27T08:20:01Z",
          "updatedAt": "2026-02-27T08:20:01Z"
        }
      ]
    },
    {
      "number": 62,
      "id": "I_kwDONyB6uM7uZF9X",
      "title": "Lots of broken citations",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/issues/62",
      "state": "OPEN",
      "author": "martinthomson",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "kramdown-rfc won't expand references that appear in code.  There are lots of braces in code blocks that seem like they want to be references, but they are just code.",
      "createdAt": "2026-02-27T07:14:05Z",
      "updatedAt": "2026-02-27T07:14:05Z",
      "closedAt": null,
      "comments": []
    }
  ],
  "pulls": [
    {
      "number": 1,
      "id": "PR_kwDONyB6uM6JkhuC",
      "title": "Cleanup pass over the spec draft",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/1",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Documentation / spec updates:\r\n- Removed Hash from ciphersuite dependency\r\n- Added explanation of why we are using KVAC instead of BBS\r\n- Clarified that the issuance protocol uses Pedersen commitments, for perfect privacy\r\n- Corrected the incorrect presentation proof scalar descriptions\r\n\r\nBehavioral changes:\r\n- Changed the presentationState definition to generate the nonce only when needed (instead of proactively generating / holding onto a presentationNonce). Updated the proof of concept accordingly.\r\n- Changed the proof of concept presentationState to have nonces start at 0 (instead of 1)\r\n-  Tightened the presentation limit bounds to 0 <= nonce < rateLimit (was previously allowing for nonce = rateLimit)\r\n\r\nFixes:\r\n- Added `x2` to the ServerKey test vectors (previously had a typo, repeated `x1` twice).\r\n\r\nSome things I have questions about:\r\n- Why aren't the presentation proof statements (5.4) rendering correctly? I don't see anything that should result in a formatting error, but the markdown seems unhappy with the Tag definition.",
      "createdAt": "2025-01-31T00:51:57Z",
      "updatedAt": "2025-01-31T13:15:02Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "9cfc01da472c850860006c4a0b0570a477dca2e2",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "cathie/cleanup",
      "headRefOid": "b67e765525d3a80637e67095d5019049eb950a5f",
      "closedAt": "2025-01-31T13:15:02Z",
      "mergedAt": "2025-01-31T13:15:02Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "0f1198a859c747541f23185b1707f66433a315b5"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM6aLi0m",
          "commit": {
            "abbreviatedOid": "34e4d55"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-01-31T13:12:44Z",
          "updatedAt": "2025-01-31T13:12:44Z",
          "comments": [
            {
              "originalPosition": 416,
              "body": "```suggestion\r\n```",
              "createdAt": "2025-01-31T13:12:44Z",
              "updatedAt": "2025-01-31T13:12:44Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM6aLjq6",
          "commit": {
            "abbreviatedOid": "68d20a7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2025-01-31T13:13:23Z",
          "updatedAt": "2025-01-31T13:14:08Z",
          "comments": [
            {
              "originalPosition": 419,
              "body": "```suggestion\r\nThe BBS anonymous credential scheme, as detailed in {{BBS}} and its variants, is efficient and publicly verifiable, but requires pairings for verification. This is problematic for adoption because pairings are not supported as widely in software and hardware as non-pairing elliptic curves.\r\n```",
              "createdAt": "2025-01-31T13:13:24Z",
              "updatedAt": "2025-01-31T13:14:08Z"
            },
            {
              "originalPosition": 421,
              "body": "```suggestion\r\nIt is possible to construct a keyed-verification variant of BBS which doesn't use pairings, as discussed in {{BBDT17}} and {{REVISITING_KVAC}}. However these keyed-verification BBS variants require more analysis, proofs of security properties, and review to be considered mature enough for safe deployment.\r\n```",
              "createdAt": "2025-01-31T13:14:01Z",
              "updatedAt": "2025-01-31T13:14:08Z"
            }
          ]
        }
      ]
    },
    {
      "number": 2,
      "id": "PR_kwDONyB6uM6JrAx9",
      "title": "Add Privacy Pass integration draft",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/2",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Questions:\r\n1. Should requestContext be the entire challenge, or just issuer name? I think just the issuer name, letting the server use the rest of the TokenChallenge as the presentationContext.\r\n2. Do we need to include the rate limit as a challenge extension? (I think so)\r\n3. How should we encode nonce on the wire? I think 32 bits is probably fine? This does impose an upper bound on the actual rate limit, of course.\r\n4. What do we need in security considerations for the Privacy Pass draft?",
      "createdAt": "2025-01-31T17:53:46Z",
      "updatedAt": "2025-01-31T21:06:17Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "b3bb6710d338ed8fd0825f6909880e445832c9c5",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "caw/pp",
      "headRefOid": "694d54e8c735ad5e75953d4c15965a773a4089aa",
      "closedAt": "2025-01-31T21:06:17Z",
      "mergedAt": "2025-01-31T21:06:17Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "0e51dff5a7e76eaddc27bf66c7bd974148a837ef"
      },
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "1. I think that the requestContext should be as minimal as possible. So if we can have it just be the issuer name, that would be ideal (allows for more flexibility upon presentation).\r\n2. By \"challenge extension\" you mean another field in the TokenChallenge sent from the Client Origin? I had been thinking that the rate limit gets sent with the server public keys - so that can be in the TokenChallenge itself, or alongside it.\r\n   - Though looking through the origin-provided inputs, I see that the Privacy Pass spec has the origin sending the Public Key ID (issuer_key_id), instead of the public key itself. Since the client needs the full public key for the FinalizeCredential call, when does it receive the full public key? Or is this step considered to be out-of-band and not defined by the spec?\r\n3. I think 32 bits is fine. ",
          "createdAt": "2025-01-31T19:03:52Z",
          "updatedAt": "2025-01-31T19:03:52Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 3,
      "id": "PR_kwDONyB6uM6J6Zt9",
      "title": "Add privacy pass security considerations",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/3",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Added some security considerations to the privacy pass section, working off of other specs:\r\n\r\nhttps://datatracker.ietf.org/doc/html/draft-ietf-privacypass-architecture-16#section-6\r\nhttps://datatracker.ietf.org/doc/draft-ietf-privacypass-public-metadata-issuance/\r\nhttps://datatracker.ietf.org/doc/rfc9497/\r\n\r\nSome of this repeats the security considerations in the ARC CFRG spec (eg Client Issuance Unlinkability), I'm not sure if it's okay to repeat across both specs, or where they would belong best.",
      "createdAt": "2025-02-03T22:24:38Z",
      "updatedAt": "2025-02-04T01:13:12Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "a85a40173e014733ffe96e625c73399b43d19e13",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "cathie/pp-security",
      "headRefOid": "91c301950da1cc6dbb71a062425d256af4e30f2c",
      "closedAt": "2025-02-04T01:13:12Z",
      "mergedAt": "2025-02-04T01:13:12Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "2f07972788431435b16750677c88ca2f14e33cf1"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM6adea4",
          "commit": {
            "abbreviatedOid": "91c3019"
          },
          "author": "tfpauly",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2025-02-04T00:15:17Z",
          "updatedAt": "2025-02-04T00:15:17Z",
          "comments": []
        }
      ]
    },
    {
      "number": 4,
      "id": "PR_kwDONyB6uM6KB0It",
      "title": "Collapse security considerations",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/4",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "We defined a lot of these things in the architecture document, so I just used that language. Also, I fixed two things: (1) we don't send \"presentations,\" we send \"tokens\", and (2) the presentation context is the token challenge (and some other stuff); it's not some agreed-upon value between client and origin/issuer.",
      "createdAt": "2025-02-04T17:09:09Z",
      "updatedAt": "2025-02-04T20:17:31Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "2f07972788431435b16750677c88ca2f14e33cf1",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "caw/pp",
      "headRefOid": "6643014bb397ef96bd592ab7db2df337d4982983",
      "closedAt": "2025-02-04T20:17:31Z",
      "mergedAt": "2025-02-04T20:17:31Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "f9f8ca5daa5442fc9b9376d44c1a1e46e8298531"
      },
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "LGTM! Thanks for cleaning up the wording, I wasn't sure about some of the terminology.",
          "createdAt": "2025-02-04T20:13:25Z",
          "updatedAt": "2025-02-04T20:14:16Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM6amn2h",
          "commit": {
            "abbreviatedOid": "6643014"
          },
          "author": "tfpauly",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2025-02-04T19:14:01Z",
          "updatedAt": "2025-02-04T19:14:01Z",
          "comments": []
        }
      ]
    },
    {
      "number": 5,
      "id": "PR_kwDONyB6uM6KGYl5",
      "title": "Reference implementation / test vector updates",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/5",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Small changes and cleanups I came across while working on interoperability for the test vectors - mostly domain separator updates. I also removed some unnecessary fields from the Presentation (generatorT, U_prime) and added presentation_context. \r\n\r\nIMO the test vectors should have presentation_context, for presentation creation. I see that generatorT is included currently, which can be a proxy for presentation_context, but it seems better to use presentation_context directly (it also is a bit weird to make the ARC implementation take in a generatorT from a test vector, during presentation creation), so I removed it.",
      "createdAt": "2025-02-05T07:52:27Z",
      "updatedAt": "2025-02-07T21:26:39Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "f9f8ca5daa5442fc9b9376d44c1a1e46e8298531",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "cathie/testvectors",
      "headRefOid": "497187e26cf19295f769c9c3c68fd83c640a90d5",
      "closedAt": "2025-02-05T23:03:30Z",
      "mergedAt": "2025-02-05T23:03:30Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "f94fdf1fac0bfd6b5a92c530c915adebb72add49"
      },
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Ok, I'm happy to keep the labels in line with the spec (so as not to change the spec).\r\n\r\nBut even then, we'll need a few tweaks here and there in the poc, like capitalizing \"tag\" in `generator_T = hash_to_group(self.presentation_context, to_bytes(\"tag\"))` to get them in sync.",
          "createdAt": "2025-02-05T16:49:39Z",
          "updatedAt": "2025-02-05T16:57:33Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "The reference implementation is now in line with the spec, from what I can tell. I didn't change the spec itself.\r\nAnd I updated the presentation context encoding to hex. \r\nPTAL :)",
          "createdAt": "2025-02-05T18:00:05Z",
          "updatedAt": "2025-02-05T18:00:05Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM6aukrC",
          "commit": {
            "abbreviatedOid": "e1b90d1"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "The label changes don't match the spec. Can we please keep them as-is?",
          "createdAt": "2025-02-05T14:11:08Z",
          "updatedAt": "2025-02-05T14:12:03Z",
          "comments": [
            {
              "originalPosition": 13,
              "body": "This should be in hex like the other test vectors.",
              "createdAt": "2025-02-05T14:11:08Z",
              "updatedAt": "2025-02-05T14:12:03Z"
            },
            {
              "originalPosition": 5,
              "body": "This doesn't match the spec:\r\n\r\n```\r\n  generatorT = G.HashToGroup(presentationContext, \"Tag\")\r\n```",
              "createdAt": "2025-02-05T14:11:40Z",
              "updatedAt": "2025-02-05T14:12:03Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM6azdXT",
          "commit": {
            "abbreviatedOid": "497187e"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2025-02-05T23:03:25Z",
          "updatedAt": "2025-02-05T23:03:25Z",
          "comments": []
        }
      ]
    },
    {
      "number": 6,
      "id": "PR_kwDONyB6uM6KeBnn",
      "title": "Cleanup tasks",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/6",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Cleanup / documentation tasks:\r\n- Some proof documentation was incorrect - specifically, the comments for statements 5a and 5b in the response proof were in the wrong order. \r\n- Added request_context to the test vectors, so we can test that request_context gets hashed correctly to become m2. \r\n\r\nPotential additional tasks: \r\n- Currently, the ProofParticipant initializer ignores the input label, instead setting it to an empty string. We should actually use the label, to differentiate different proofs. However, I didn't make that change in this PR because it changes all the proof test vectors, which would be quite disruptive. Maybe this fix can get rolled into the next change the significantly alters the test vectors.\r\n- Add more test vectors, including negative cases.",
      "createdAt": "2025-02-07T21:09:57Z",
      "updatedAt": "2025-02-12T16:38:16Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "f94fdf1fac0bfd6b5a92c530c915adebb72add49",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "cathie/nit",
      "headRefOid": "9f1abc04db5602cb197b180ee64944f3f569cf10",
      "closedAt": "2025-02-12T16:19:06Z",
      "mergedAt": "2025-02-12T16:19:06Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "7c4fa7e7b36d94ba140f6ef36a3b71cd4f9529d1"
      },
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "@cathieyun this looks good, but I think we should make the ProofParticipant label change here. ",
          "createdAt": "2025-02-11T21:34:51Z",
          "updatedAt": "2025-02-11T21:34:51Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Done - I fixed the ProofParticipant label at initialization, and updated the test vectors accordingly. I also renamed the \"PresentationProof\" label to \"CredentialPresentation\" to have it line up with the \"CredentialRequest\" and \"CredentialResponse\" labels (that was bothering me :P).\r\nPTAL!",
          "createdAt": "2025-02-11T23:43:05Z",
          "updatedAt": "2025-02-11T23:44:03Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM6bt85P",
          "commit": {
            "abbreviatedOid": "9f1abc0"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Woot!",
          "createdAt": "2025-02-12T16:19:00Z",
          "updatedAt": "2025-02-12T16:19:00Z",
          "comments": []
        }
      ]
    },
    {
      "number": 9,
      "id": "PR_kwDONyB6uM6MM1HU",
      "title": "Fixing nits",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/9",
      "state": "MERGED",
      "author": "thibmeu",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Small editorial nits",
      "createdAt": "2025-02-23T15:41:17Z",
      "updatedAt": "2025-02-25T19:54:53Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "7c4fa7e7b36d94ba140f6ef36a3b71cd4f9529d1",
      "headRepository": "thibmeu/draft-arc",
      "headRefName": "main",
      "headRefOid": "3dde9c120cd584c2ad2ff38a4f8a0445238e8911",
      "closedAt": "2025-02-25T19:54:53Z",
      "mergedAt": "2025-02-25T19:54:53Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "9779d28674e161a1cea3962be58bb6796ebbb50e"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM6dPLoU",
          "commit": {
            "abbreviatedOid": "49371a3"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-02-24T18:03:07Z",
          "updatedAt": "2025-02-24T18:03:07Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "```suggestion\r\n  ARC: I-D.draft-yun-cfrg-arc\r\n```",
              "createdAt": "2025-02-24T18:03:07Z",
              "updatedAt": "2025-02-24T18:03:07Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM6dPOIq",
          "commit": {
            "abbreviatedOid": "3dde9c1"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Thanks!",
          "createdAt": "2025-02-24T18:04:05Z",
          "updatedAt": "2025-02-24T18:04:05Z",
          "comments": []
        },
        {
          "id": "PRR_kwDONyB6uM6dPPgy",
          "commit": {
            "abbreviatedOid": "49371a3"
          },
          "author": null,
          "authorAssociation": "NONE",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-02-24T18:04:38Z",
          "updatedAt": "2025-02-24T18:04:38Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "I did not know that was supported. That's nice",
              "createdAt": "2025-02-24T18:04:38Z",
              "updatedAt": "2025-02-24T18:04:38Z"
            }
          ]
        }
      ]
    },
    {
      "number": 13,
      "id": "PR_kwDONyB6uM6MiM6G",
      "title": "Add new TokenChallenge to separate credential and token construction",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/13",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "cc @thibmeu, @tfpauly ",
      "createdAt": "2025-02-25T21:20:20Z",
      "updatedAt": "2025-03-03T17:45:12Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "9779d28674e161a1cea3962be58bb6796ebbb50e",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "caw/new-challenge",
      "headRefOid": "8284c0fdad2def4d1153f7ad1dc6fe713779c733",
      "closedAt": "2025-03-03T17:45:12Z",
      "mergedAt": "2025-03-03T17:45:12Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "08c54fd64f198e85d8a90827a45944cb52e5fec3"
      },
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "LGTM, thanks for adding this - this will help with credential expiry enforcement!",
          "createdAt": "2025-02-25T21:26:47Z",
          "updatedAt": "2025-02-25T21:26:47Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM6djQIf",
          "commit": {
            "abbreviatedOid": "6059e57"
          },
          "author": "thibmeu",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-02-26T06:41:00Z",
          "updatedAt": "2025-02-26T06:48:27Z",
          "comments": [
            {
              "originalPosition": 13,
              "body": "This matches the ([yet-unwritten](https://datatracker.ietf.org/doc/html/draft-hendrickson-pp-attesterissuer-00#name-attester-to-issuer-request)) convention of putting token_type as the first byte.",
              "createdAt": "2025-02-26T06:41:00Z",
              "updatedAt": "2025-02-26T06:48:27Z"
            },
            {
              "originalPosition": 18,
              "body": "It would be great to reorder to have a structure that extends the Token Challenge Structure defined in [Section 2.1.1 of RFC9577](https://datatracker.ietf.org/doc/html/rfc9577#name-token-challenge-structure)\r\n```suggestion\r\n    opaque issuer_name<1..2^16-1>;\r\n    opaque redemption_context<0..32>;\r\n    opaque origin_info<0..2^16-1>;\r\n    opaque credential_context<0..32>;\r\n} TokenChallenge;\r\n```",
              "createdAt": "2025-02-26T06:44:32Z",
              "updatedAt": "2025-02-26T06:48:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM6drAQu",
          "commit": {
            "abbreviatedOid": "6059e57"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-02-26T17:33:26Z",
          "updatedAt": "2025-02-26T17:33:27Z",
          "comments": [
            {
              "originalPosition": 18,
              "body": "I thought about extending it, but opted not to since this is new parsing code based on the token type anyway. What do you see as the value in extending it?",
              "createdAt": "2025-02-26T17:33:26Z",
              "updatedAt": "2025-02-26T17:33:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM6dx--a",
          "commit": {
            "abbreviatedOid": "6059e57"
          },
          "author": "thibmeu",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-02-27T09:18:51Z",
          "updatedAt": "2025-02-27T09:18:51Z",
          "comments": [
            {
              "originalPosition": 18,
              "body": "Mostly to match what exists. I agree this would be parsed anyway, but given this is the TokenChallenge it takes inspiration from at the moment could have the same order, I feel it makes sense to do it.",
              "createdAt": "2025-02-27T09:18:51Z",
              "updatedAt": "2025-02-27T09:18:51Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM6d15Fp",
          "commit": {
            "abbreviatedOid": "6059e57"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-02-27T15:17:01Z",
          "updatedAt": "2025-02-27T15:17:01Z",
          "comments": [
            {
              "originalPosition": 18,
              "body": "I don't feel strongly, so I'm happy to take this.",
              "createdAt": "2025-02-27T15:17:01Z",
              "updatedAt": "2025-02-27T15:17:01Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM6d16NK",
          "commit": {
            "abbreviatedOid": "8284c0f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-02-27T15:18:22Z",
          "updatedAt": "2025-02-27T15:18:22Z",
          "comments": [
            {
              "originalPosition": 13,
              "body": "Isn't this specified [in the auth-scheme draft](https://ietf-wg-privacypass.github.io/base-drafts/draft-ietf-privacypass-auth-scheme.html#name-token-challenge-structure)?\r\n\r\n```\r\nAll token challenges MUST begin with a 2-octet integer that defines the token type, in network byte order. This type indicates the issuance protocol used to generate the token and determines the structure and semantics of the rest of the structure. Values are registered in an IANA registry, [Section 6.2](https://ietf-wg-privacypass.github.io/base-drafts/draft-ietf-privacypass-auth-scheme.html#token-types). Client MUST ignore challenges with token types they do not support.[\u00b6](https://ietf-wg-privacypass.github.io/base-drafts/draft-ietf-privacypass-auth-scheme.html#section-2.1.1-2)\r\n```",
              "createdAt": "2025-02-27T15:18:22Z",
              "updatedAt": "2025-02-27T15:18:22Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM6d2yQD",
          "commit": {
            "abbreviatedOid": "6059e57"
          },
          "author": "thibmeu",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-02-27T16:27:29Z",
          "updatedAt": "2025-02-27T16:27:29Z",
          "comments": [
            {
              "originalPosition": 13,
              "body": "You are right. My bad. For the token challenge it works.",
              "createdAt": "2025-02-27T16:27:29Z",
              "updatedAt": "2025-02-27T16:27:29Z"
            }
          ]
        }
      ]
    },
    {
      "number": 15,
      "id": "PR_kwDONyB6uM6NDipV",
      "title": "Remove extra response from presentation struct",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/15",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Fix a typo where I had an extra response field in the presentation struct",
      "createdAt": "2025-03-02T06:56:23Z",
      "updatedAt": "2025-03-03T17:44:56Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "9779d28674e161a1cea3962be58bb6796ebbb50e",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "cathie/typofix",
      "headRefOid": "200ae5f53265189174d80a560cfc4fba88510784",
      "closedAt": "2025-03-03T17:44:55Z",
      "mergedAt": "2025-03-03T17:44:55Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "bf1ab809e30959ab97c743eb402d28fed786c37b"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM6eH4yg",
          "commit": {
            "abbreviatedOid": "200ae5f"
          },
          "author": "clangreformers",
          "authorAssociation": "NONE",
          "state": "APPROVED",
          "body": "I have verified the change with test vectors. This change also matches [5.4.1. ]Presentation Proof Creation and [5.4.2. ] Presentation Proof Verification.\r\n\r\n-- Yingxian Wang",
          "createdAt": "2025-03-03T00:19:26Z",
          "updatedAt": "2025-03-03T00:19:26Z",
          "comments": []
        },
        {
          "id": "PRR_kwDONyB6uM6ePV5i",
          "commit": {
            "abbreviatedOid": "200ae5f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2025-03-03T17:44:49Z",
          "updatedAt": "2025-03-03T17:44:49Z",
          "comments": []
        }
      ]
    },
    {
      "number": 26,
      "id": "PR_kwDONyB6uM6RDrh6",
      "title": "Clean up specs for clarity",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/26",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Addresses the following issues:\r\nhttps://github.com/chris-wood/draft-arc/issues/16\r\nhttps://github.com/chris-wood/draft-arc/issues/18\r\nhttps://github.com/chris-wood/draft-arc/issues/20\r\nhttps://github.com/chris-wood/draft-arc/issues/22",
      "createdAt": "2025-04-02T09:26:02Z",
      "updatedAt": "2025-04-15T16:05:36Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "08c54fd64f198e85d8a90827a45944cb52e5fec3",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "cathie/spec-cleanup",
      "headRefOid": "dd47f5f07c30cbd36f9fd679d5ea965ad85e48a6",
      "closedAt": "2025-04-15T16:05:36Z",
      "mergedAt": "2025-04-15T16:05:36Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "061e446a4eeed977735f06386f570f5ad1296d9d"
      },
      "comments": [
        {
          "author": "karulont",
          "authorAssociation": "NONE",
          "body": "> The server implementation won't parse out the tag, so it can't reasonably enforce double spending on that value...\r\n\r\nWhy not?\r\nImplementation in swift-crypto already exposes the tag:\r\nhttps://github.com/apple/swift-crypto/blob/main/Sources/_CryptoExtras/ARC/ARC%2BAPI.swift#L245\r\nStoring the whole presentation vs just the tag has performance implications.",
          "createdAt": "2025-04-03T15:43:52Z",
          "updatedAt": "2025-04-03T15:44:14Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Discussed with Chris - for Privacy Pass interoperability, the *ideal* behavior which would fit cleanly into the current Privacy Pass workflow, would be if the server could store the entire ARC token for double spending checks (this maps most cleanly to how the server currently stores the entire RSA signature value for double spend checks). So, I understand the motivation/reasoning here.\r\n\r\nHowever for ARC, this isn't possible because the tag is the only item in the presentation which is \"weight bearing\" for rate limiting. That is, we can only use the tag for double-spend prevention. If we tried to use the whole presentation for double-spend prevention, it would not work because it is possible to make multiple presentations with the same tag, but where the other presentation elements are different (since they are re-randomized each time). So it would be trivial for a malicious client to exceed the rate limit by reusing the same nonce for multiple presentations.",
          "createdAt": "2025-04-12T04:26:56Z",
          "updatedAt": "2025-04-12T04:26:56Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Chris gave me the go-ahead to merge this PR.",
          "createdAt": "2025-04-15T16:05:32Z",
          "updatedAt": "2025-04-15T16:05:32Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM6jIuoY",
          "commit": {
            "abbreviatedOid": "06f0496"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "Some nits on double spending. The server implementation won't parse out the tag, so it can't reasonably enforce double spending on that value. I think it's probably fine to simply say that the relevant presentation values (nonce and presentation) itself cannot be spent more than once. ",
          "createdAt": "2025-04-02T16:54:09Z",
          "updatedAt": "2025-04-02T16:59:57Z",
          "comments": [
            {
              "originalPosition": 32,
              "body": "```suggestion\r\nImplementation-specific steps: to prevent double spending, the Origin should perform a check that the\r\n```",
              "createdAt": "2025-04-02T16:54:09Z",
              "updatedAt": "2025-04-02T16:59:57Z"
            },
            {
              "originalPosition": 33,
              "body": "```suggestion\r\npresentation (`presentation_nonce` and `presentation`) has not previously been seen for a given request and credential context. It then stores the presentation values for use in future double\r\n```",
              "createdAt": "2025-04-02T16:54:42Z",
              "updatedAt": "2025-04-02T16:59:57Z"
            },
            {
              "originalPosition": 34,
              "body": "```suggestion\r\nspending checks. To reduce the overhead of performing double spend checks, the Origin can store and\r\n```",
              "createdAt": "2025-04-02T16:54:49Z",
              "updatedAt": "2025-04-02T16:59:57Z"
            },
            {
              "originalPosition": 35,
              "body": "```suggestion\r\nlook up the presentation values corresponding to the associated request_context and presentation_context values.\r\n```",
              "createdAt": "2025-04-02T16:57:06Z",
              "updatedAt": "2025-04-02T16:59:57Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM6koTR_",
          "commit": {
            "abbreviatedOid": "06f0496"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-04-12T04:13:02Z",
          "updatedAt": "2025-04-12T04:13:02Z",
          "comments": [
            {
              "originalPosition": 33,
              "body": "The server should just store the tag for double spending, as the tag is the \"weight bearing\" field for rate limiting purposes. The other presentation elements may be re-randomized (and therefore look different) even if the rate limit is exceeded (eg if a nonce is reused), so checking the whole presentation is not the right way to enforce rate limiting.",
              "createdAt": "2025-04-12T04:13:02Z",
              "updatedAt": "2025-04-12T04:13:02Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM6koTS9",
          "commit": {
            "abbreviatedOid": "06f0496"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-04-12T04:13:17Z",
          "updatedAt": "2025-04-12T04:13:17Z",
          "comments": [
            {
              "originalPosition": 35,
              "body": "Same as above.",
              "createdAt": "2025-04-12T04:13:17Z",
              "updatedAt": "2025-04-12T04:13:17Z"
            }
          ]
        }
      ]
    },
    {
      "number": 27,
      "id": "PR_kwDONyB6uM6RHDAk",
      "title": "Move ARC to use P256 by default",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/27",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "For performance, we can move from P384 to P256 as the default curve. \r\n- This will give us approximately an order of magnitude speedup.\r\n- This is acceptable from a security standpoint for most applications - P384 was originally chosen as a very conservative starting point, but with the understanding that it may be overly conservative at the cost of performance.\r\n",
      "createdAt": "2025-04-02T15:23:03Z",
      "updatedAt": "2025-04-14T22:56:08Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "08c54fd64f198e85d8a90827a45944cb52e5fec3",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "cathie/p256",
      "headRefOid": "21256c089aca2b62faf5cb5e2de724ae0fcaa8fc",
      "closedAt": "2025-04-14T22:56:04Z",
      "mergedAt": "2025-04-14T22:56:04Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "3793df49d3813daf3123dc305c222404426b6b81"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM6jIhvo",
          "commit": {
            "abbreviatedOid": "21256c0"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2025-04-02T16:33:13Z",
          "updatedAt": "2025-04-02T16:33:13Z",
          "comments": []
        }
      ]
    },
    {
      "number": 31,
      "id": "PR_kwDONyB6uM6beW5g",
      "title": "Clarify unlinkability properties",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/31",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Addresses https://github.com/chris-wood/draft-arc/issues/10 by adding clarifying that the original analysis for for credential request, and adding a privacy analysis for credential response (issuance).",
      "createdAt": "2025-06-20T21:04:35Z",
      "updatedAt": "2025-08-06T20:43:28Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "061e446a4eeed977735f06386f570f5ad1296d9d",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "stat-anon",
      "headRefOid": "63da92a60f0c7f2ac3bd66021ac22bdb62ec3b2d",
      "closedAt": "2025-06-23T20:54:38Z",
      "mergedAt": "2025-06-23T20:54:38Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "be865e28cae741946a81ba5bd064f71f21767b4d"
      },
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Added some changes suggested by Michele.",
          "createdAt": "2025-06-23T20:52:07Z",
          "updatedAt": "2025-06-23T20:52:07Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM6v6Cjp",
          "commit": {
            "abbreviatedOid": "e36f826"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "This LGTM with the suggested changes!",
          "createdAt": "2025-06-23T18:56:06Z",
          "updatedAt": "2025-06-23T18:56:19Z",
          "comments": [
            {
              "originalPosition": 13,
              "body": "```suggestion\r\nHowever, an adversary breaking the discrete log (e.g., a quantum adversary) can find pairs `(x0, x0Blinding)` and `(x0', x0Blinding')` both committing to `X0` and use them to issue different credentials. This capability would let the adversary partitioning the client anonymity set by linking clients to the underlying secret used for credential issuance, i.e., `x0` or `x0'`. This requires an active attack and therefore is not an immediate concern.\r\n\r\nStatistical anonymity is possible by committing to `x0` and x0Blinding` separately, as in {{REVISITING_KVAC}}. However, the security of this construction requires additional analysis.\r\n```",
              "createdAt": "2025-06-23T18:56:06Z",
              "updatedAt": "2025-06-23T18:56:19Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM6v6DI4",
          "commit": {
            "abbreviatedOid": "e36f826"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-06-23T18:57:11Z",
          "updatedAt": "2025-06-23T18:57:11Z",
          "comments": [
            {
              "originalPosition": 13,
              "body": "I don't think we need to comment on performance for the alternative commitment scheme since security is the primary reason we would not use it. ",
              "createdAt": "2025-06-23T18:57:11Z",
              "updatedAt": "2025-06-23T18:57:11Z"
            }
          ]
        }
      ]
    },
    {
      "number": 32,
      "id": "PR_kwDONyB6uM6becYP",
      "title": "Remove P384 from the list of ARC supported curves",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/32",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "From discussion on the CFRG list and with authors, we decided to move to P256 instead of P384 for performance reasons. I kept P384 as a curve option originally, but it seems better to remove it for several reasons:\r\n- We want to move the proof to use the sigma proof spec, which only supports P256: https://github.com/mmaker/draft-zkproof-sigma-protocols/blob/main/draft-orru-zkproof-sigma-protocols.md#ciphersuites-ciphersuites\r\n- Implementors would prefer fewer rather than more curves. This will also help interoperability and adoption. Eg from the cfrg mailing list, on the call for adoption for sigma protocols, Chris Patton says:\r\n> As an implementer, in general I think fewer choices for curves is always better. In this case, I would rather have P384 only than a bunch of different options (including P256, ristretto, decaf, etc.). It just strikes me as odd to choose P384 over something smaller and more widely used, like P256. For TLS for example, both X25519 and P256 are much, much more common than P384.",
      "createdAt": "2025-06-20T21:19:37Z",
      "updatedAt": "2025-06-23T18:37:17Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "061e446a4eeed977735f06386f570f5ad1296d9d",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "update-curves",
      "headRefOid": "baeff348cff7147dae75cb568fac472542ede7c2",
      "closedAt": "2025-06-23T18:37:17Z",
      "mergedAt": "2025-06-23T18:37:17Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "01234b0dbcb18d7e2109898ed4e7acbb04502c2c"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM6v50vj",
          "commit": {
            "abbreviatedOid": "baeff34"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2025-06-23T18:37:04Z",
          "updatedAt": "2025-06-23T18:37:04Z",
          "comments": []
        }
      ]
    },
    {
      "number": 33,
      "id": "PR_kwDONyB6uM6idmvY",
      "title": "Fix ARC section references, open issues",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/33",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Tried to push the a new tag to the privacy pass datatracker, but it failed because of \"no link definition\" errors:\r\nhttps://github.com/chris-wood/draft-arc/actions/runs/16788723485/job/47545705794\r\n\r\nFixing those errors here.",
      "createdAt": "2025-08-06T21:20:58Z",
      "updatedAt": "2025-08-06T21:30:30Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "be865e28cae741946a81ba5bd064f71f21767b4d",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "cathie/pp-lint",
      "headRefOid": "93d986fc3bd3f9499b599f1ad14e16c6c3bac91f",
      "closedAt": "2025-08-06T21:30:30Z",
      "mergedAt": "2025-08-06T21:30:30Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "da1c77459c99717790b9068e4c5fbdd995076a82"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 34,
      "id": "PR_kwDONyB6uM6j6J7i",
      "title": "Add prover random blindings to test vectors.",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/34",
      "state": "MERGED",
      "author": "armfazh",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Random blindings need to be provided for reproducing the construction of proofs.",
      "createdAt": "2025-08-16T00:09:13Z",
      "updatedAt": "2025-09-13T17:44:46Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "da1c77459c99717790b9068e4c5fbdd995076a82",
      "headRepository": "armfazh/draft-arc",
      "headRefName": "track_blindings",
      "headRefOid": "82707c4d987bc348ff3c5b14ec7cdbc3f8a7a11d",
      "closedAt": "2025-09-13T17:44:46Z",
      "mergedAt": "2025-09-13T17:44:46Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "24dac6275c1660a973e03a584fbe07733f54a5a8"
      },
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Running the integration workflows. Thanks for your contribution, I will take a look.",
          "createdAt": "2025-09-13T17:32:49Z",
          "updatedAt": "2025-09-13T17:32:49Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "LGTM, thanks for adding those blinding factors!",
          "createdAt": "2025-09-13T17:44:42Z",
          "updatedAt": "2025-09-13T17:44:42Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 35,
      "id": "PR_kwDONyB6uM6kVOji",
      "title": "Add challenge digest to privacypass spec",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/35",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, the default privacy pass token structure is:\r\n```\r\nstruct {\r\n    uint16_t token_type;\r\n    uint8_t nonce[32];\r\n    uint8_t challenge_digest[32];\r\n    uint8_t token_key_id[Nid];\r\n    uint8_t authenticator[Nk];\r\n} Token;\r\n```\r\n\r\nThe ARC token structure is:\r\n```\r\nstruct {\r\n    uint16_t token_type = 0xE5AC; /* Type ARC(P-256) */\r\n    uint8_t issuer_key_id[Nid];\r\n    uint32_t presentation_nonce;\r\n    uint8_t presentation[Npresentation];\r\n} Token;\r\n```\r\n\r\nWhere we have a parallel between the following fields:\r\n- token_type is the same\r\n- token_key_id is the same as issuer_key_id in function. Different name because there is no longer the concept of the \"token authentication key\", in ARC the issuer key ID is the same thing as the authentication key.\r\n- nonce is sort of the same as the presentation_nonce, in that it's revealed at presentation time and must be unique. But unlike in the base token protocol, one credential can be made with many nonces, so we wanted the field names to be different.\r\n- We don't need to send the challenge_digest, as this is assumed to be already known at the recipient side. This saves us some space.\r\n- The authenticator for PAT was an RSA signature; the presentation is the equivalent of this, which ties the token to all the preceding in formation, in a way that can only be verified by the issuer key.\r\n\r\nHowever, upon further consideration, we still want to have a `challenge_digest` as the recipient may have multiple challenge_digests that are valid, and we don't want to make them try all of them to figure out which to use. So, this PR adds `challenge_digest` back to the struct. It also reorders the fields so that they have the same order as the default privacy pass protocol structure.",
      "createdAt": "2025-08-19T16:35:39Z",
      "updatedAt": "2025-08-25T18:27:54Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "da1c77459c99717790b9068e4c5fbdd995076a82",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "cathie/challenge_digest",
      "headRefOid": "8c9778ed7710efe4f261e5e9f2ee67ccd08af12a",
      "closedAt": "2025-08-25T18:27:54Z",
      "mergedAt": "2025-08-25T18:27:54Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "7f5a31b610d7398e25d6dd1551a46a0674611429"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM66v18y",
          "commit": {
            "abbreviatedOid": "4f28f2d"
          },
          "author": "clangreformers",
          "authorAssociation": "NONE",
          "state": "APPROVED",
          "body": "LGTM",
          "createdAt": "2025-08-19T16:47:58Z",
          "updatedAt": "2025-08-19T16:47:58Z",
          "comments": []
        },
        {
          "id": "PRR_kwDONyB6uM67QlTg",
          "commit": {
            "abbreviatedOid": "4f28f2d"
          },
          "author": "tfpauly",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2025-08-21T17:30:00Z",
          "updatedAt": "2025-08-21T17:30:05Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "The structure field definitions below also need to be updated.",
              "createdAt": "2025-08-21T17:30:00Z",
              "updatedAt": "2025-08-21T17:30:05Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM67Q7QO",
          "commit": {
            "abbreviatedOid": "4f28f2d"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-08-21T18:04:17Z",
          "updatedAt": "2025-08-21T18:04:17Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "Sorry I missed that, updated now!",
              "createdAt": "2025-08-21T18:04:17Z",
              "updatedAt": "2025-08-21T18:04:17Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM67Sx2a",
          "commit": {
            "abbreviatedOid": "8c9778e"
          },
          "author": "tfpauly",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2025-08-21T21:00:41Z",
          "updatedAt": "2025-08-21T21:00:41Z",
          "comments": []
        }
      ]
    },
    {
      "number": 37,
      "id": "PR_kwDONyB6uM6odk5m",
      "title": "Move ARC spec to use Sigma and Fiat-Shamir specs for proofs",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/37",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Removes the Schnorr proof compiler section from the ARC spec, and replaces it with the Sigma and Fiat-Shamir specs instead. Updates the proof creation and verification to use the APIs from the Sigma and Fiat-Shamir specs.\r\n\r\nTasks:\r\n- [x] Pass in an rng for the prover, since `NISigmaProtocol` needs it an rng to generate a proof. This is currently missing. Reference the Sigma protocol spec for how to define the RNG.\r\n- [x] Check if we need to define a codec for `NISigmaProtocol`? It seems like `NISigmaProtocol` needs a codec defined, but there is nowhere to define it (see section 5 in https://datatracker.ietf.org/doc/draft-irtf-cfrg-fiat-shamir/). Maybe it is set to `LinearMapCodec` by default, but I don't see that specified in the spec. -> This is fixed in https://github.com/mmaker/draft-irtf-cfrg-sigma-protocols/pull/79\r\n- [x] This also closes this issue, as it fixes the `RandomScalar()` typo: https://github.com/chris-wood/draft-arc/issues/36\r\n\r\nTasks for a follow-up PR:\r\n- Update the poc to also use the sigma protocol / fiat-shamir poc for generating proofs, and update the test vectors accordingly. \r\n  - This may involve some difficulty, as the sigma/f-s poc uses its own definition of groups that is not the same, and possibly is not compatible with, the current ARC definition of groups (which is the IETF \"boilerplate\" group definition). See this issue for more discussion on the topic: https://github.com/mmaker/draft-irtf-cfrg-sigma-protocols/issues/71#issuecomment-3288847813\r\n  - Due to the difficulties caused by the group incompatibilities, I will tackle this in a future PR once the group incompatibilities have been addressed.",
      "createdAt": "2025-09-14T05:18:21Z",
      "updatedAt": "2026-02-27T05:09:20Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "365257fc6f68c12130e9f8e0a1d209c325781297",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "cathie/sigma",
      "headRefOid": "892d9b69c37565c8949891885880b488d6420955",
      "closedAt": "2026-02-27T05:09:17Z",
      "mergedAt": "2026-02-27T05:09:17Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "167685551557c20eb45b792d168b810bd2fb475b"
      },
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "I truncated \"artwork\" to 70 columns, and also fixed the RandomScalar typo which is referenced here:\r\nhttps://github.com/chris-wood/draft-arc/issues/36",
          "createdAt": "2025-09-17T06:00:07Z",
          "updatedAt": "2025-09-17T06:00:07Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Updated the ARC spec to use the updated NIZK class and instances, which I added here:\r\nhttps://github.com/mmaker/draft-irtf-cfrg-sigma-protocols/pull/79\r\n\r\nThis PR should wait until the Sigma/F-S PR goes in first, to make sure there aren't more changes in the Sigma/F-S API.",
          "createdAt": "2025-09-24T04:16:15Z",
          "updatedAt": "2025-09-24T04:16:15Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Looks like we did indeed have more changes in the Sigma/F-S API since I put together this PR.\r\nI will park this PR for now, as we wait for those changes to get resolved / settle, so I don't repeatedly update it.",
          "createdAt": "2025-09-27T03:50:05Z",
          "updatedAt": "2025-09-27T03:50:05Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "As the Sigma/F-S PR is nearing finalization, I have updated this PR to be in line with that:\r\nhttps://github.com/mmaker/draft-irtf-cfrg-sigma-protocols/pull/79/files\r\n\r\nSo this should now be in sync, and ready to merge in once that PR is merged ^.\r\nWill share this with the ACT folks so they can use it as reference (and potentially in the process, double check that this spec's usage of sigma/f-s looks reasonable :) )",
          "createdAt": "2025-10-07T22:43:32Z",
          "updatedAt": "2025-10-07T22:43:32Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Ah I missed one thing, which is that the sigma protocol needs an `rng` but I don't pass that into the ARC API anywhere. Will need to add that! The difficulty with adding an `rng` is that it's not actually well specified in the underlying sigma spec, as pointed out in the audit:\r\nhttps://github.com/mmaker/draft-irtf-cfrg-sigma-protocols/issues/81\r\nSo, may need to follow up in the sigma/f-s spec to get better definitions.",
          "createdAt": "2025-10-10T05:55:05Z",
          "updatedAt": "2025-10-10T05:55:05Z"
        },
        {
          "author": "mmaker",
          "authorAssociation": "NONE",
          "body": "\r\nRight, however, Rust and Python provide examples for it. It\u2019s a bit tricky to describe because most programming languages have their own interfaces. For the sigma-protocols spec, perhaps we can simply say that we need a `randbytes` function that fills an array of a given length with random bytes?\r\n\r\nTo move the conversation forward, let me outline three cases where different RNGs are used:\r\n\r\n* **Devices with low entropy:** [RFC 6979](https://datatracker.ietf.org/doc/html/rfc6979) describes how to derive randomness deterministically by hashing the witness.\r\n* **Testing:** [This Sage implementation](https://github.com/mmaker/draft-irtf-cfrg-sigma-protocols/blob/main/poc/test_drng.sage) defines a deterministic random number generator for testing, which was re-implemented in Rust [here](https://github.com/mmaker/draft-irtf-cfrg-sigma-protocols/blob/main/poc/test_drng.sage).\r\n* **Additional entropy sources:** Some practitioners like to re-seed the RNG with extra inputs such as the witness, e.g., [Merlin transcripts](https://merlin.cool/transcript/rng.html).\r\n\r\nThe API in ARC doesn\u2019t seem to consider these options, but one can always construct an RNG on the fly.\r\n\r\nRegarding the RNG implementation: we had some trouble porting ARC\u2019s deterministic RNG to other languages, so we decided to make our own. Hope that doesn\u2019t cause any issues on your side.",
          "createdAt": "2025-10-18T03:26:05Z",
          "updatedAt": "2025-10-18T03:26:05Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Following up on the RNG discussion -\r\nIt is not enough for the RNG to have examples in Rust or Python, they need to be properly specified to be used in the spec. One problem/concern with the current Sigma RNG approach is that if you are using a deterministic RNG (eg for test vectors), it matters what order you pass around or call that RNG in, and any change in call ordering will completely change the test vectors.\r\n\r\nFor the RNG implementation, it does cause issues that Sigma/F-S has made its own RNG but has not properly specified it. Looking at examples of how other specs have approached specifying an RNG, we have some examples which I hope can guide the Sigma/F-S spec:\r\n- VDAF: the spec passes around seeds instead of a RNG, and uses an XOF with domain separation to expand the seed\r\nhttps://www.ietf.org/archive/id/draft-irtf-cfrg-vdaf-17.html#section-6.2 \r\n- Hybrid KEMS: the spec defines two separate functions, eg Encaps and EncapsDerand, where EncapsDerand takes in randomness for seeding the random scalar generation. Similar to the VDAF approach, but where there is an API difference between the seeded and non-seeded functions.\r\nhttps://datatracker.ietf.org/doc/html/draft-irtf-cfrg-hybrid-kems-07#appendix-A \r\n- (not as relevant, but including for thoroughness) HPKE: keys are derived from the ikm which requires a minimum amount of entropy\r\nhttps://www.rfc-editor.org/rfc/rfc9180.html#section-7.1.3 \r\n\r\nThese are all examples of how other specs have handled randomness, which are adequately specified. I think passing in an RNG that is \"tricky to describe\" will be bad for having a clearly defined spec, and the Sigma/F-S spec should instead pass in seeds or randomness into the function that require randomness (where maybe the seeds are optional, or there is a non-seeded function alternative, as in the case of Hybrid KEMs). That way, it is easier to specify how to derive randomness, and also avoids the problem I mentioned above where the order that an RNG is called is weight-bearing. WDYT?",
          "createdAt": "2026-01-13T06:26:06Z",
          "updatedAt": "2026-01-13T06:26:06Z"
        },
        {
          "author": "mmaker",
          "authorAssociation": "NONE",
          "body": "@cathieyun thanks for putting up all these references! The deterministic random number generator that we use is defined here in Rust: \r\n\r\nhttps://github.com/sigma-rs/sigma-proofs/blob/main/tests/spec/bls12_381.rs#L33-L48\r\n\r\nand here in Python: \r\n\r\nhttps://github.com/mmaker/draft-irtf-cfrg-sigma-protocols/blob/main/poc/test_drng.sage#L17-L34\r\n\r\nit's pretty straightforward to me and maybe it just needs to be specified. Can you elaborate on what you mean tricky to describe and what would be an alternative, simpler solution? I'm all for simplifying the test vector generation if we can.",
          "createdAt": "2026-01-13T16:38:25Z",
          "updatedAt": "2026-01-13T16:38:25Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Rebased to pull in the nonce hiding and spec renaming changes.",
          "createdAt": "2026-02-23T07:11:14Z",
          "updatedAt": "2026-02-23T07:11:14Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "I synced with @chris-wood separately and he said the PR looks good.\r\nWill merge this in and work on the corresponding poc updates in a separate PR.",
          "createdAt": "2026-02-27T05:09:04Z",
          "updatedAt": "2026-02-27T05:09:04Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7AOjuj",
          "commit": {
            "abbreviatedOid": "376a5fa"
          },
          "author": "cjpatton",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "Nice work! This looks correct to me, just some minor comments in line.\r\n\r\nOne high level one: Generally speaking, \"artwork\" in drafts (i.e., pseudocode contained in `~~~`) should only be 70 columns wide. Otherwise, the artwork doesn't render very well in PDF or TXT. I think a lot of drafts ignore this, and I'm not aware of an instance of the RFC editor complaining about it.",
          "createdAt": "2025-09-15T14:48:44Z",
          "updatedAt": "2025-09-15T15:02:44Z",
          "comments": [
            {
              "originalPosition": 9,
              "body": "These should be normative references, not informative ones.\r\n\r\nIn any case, there is a more convenient/conventional way to reference drafts than adding them manually to references. The first time you write `{{SIGMA}}`, write `{{!SIGMA=I-D.draft-irtf-cfrg-sigma-protocols-00}}` instead.  Then `make` will confirm this draft exists and add it as a normative reference automatically.",
              "createdAt": "2025-09-15T14:48:44Z",
              "updatedAt": "2025-09-15T19:16:04Z"
            },
            {
              "originalPosition": 257,
              "body": "This syntax enables automatic references for drafts as in my previous comment.\r\n\r\n```suggestion\r\nThis section uses the Interactive Sigma Protocol {{SIGMA}} to create zero-knowledge proofs of knowledge for various ARC operations, and the Fiat-Shamir Transform {{FIAT-SHAMIR}} to make those proofs non-interactive.\r\n```",
              "createdAt": "2025-09-15T14:49:48Z",
              "updatedAt": "2025-09-15T15:02:44Z"
            },
            {
              "originalPosition": 292,
              "body": "This doesn't appear to be valid Python syntax? How about:\r\n```suggestion\r\n  prover = NISigmaProtocol.init(iv, statement)\r\n```",
              "createdAt": "2025-09-15T14:52:40Z",
              "updatedAt": "2025-09-15T15:02:44Z"
            },
            {
              "originalPosition": 292,
              "body": "Likewise below.",
              "createdAt": "2025-09-15T14:53:18Z",
              "updatedAt": "2025-09-15T15:02:44Z"
            },
            {
              "originalPosition": 364,
              "body": "It might be a good idea to set a convenience function that allocates the variables and sets them in one call, similar to what you had before?",
              "createdAt": "2025-09-15T14:57:08Z",
              "updatedAt": "2025-09-15T15:02:44Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7ASv29",
          "commit": {
            "abbreviatedOid": "376a5fa"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-15T20:18:00Z",
          "updatedAt": "2025-09-15T20:18:00Z",
          "comments": [
            {
              "originalPosition": 292,
              "body": "Sorry, context switching from writing Swift :P",
              "createdAt": "2025-09-15T20:18:00Z",
              "updatedAt": "2025-09-15T20:18:00Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7ASxCD",
          "commit": {
            "abbreviatedOid": "376a5fa"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-15T20:18:54Z",
          "updatedAt": "2025-09-15T20:18:54Z",
          "comments": [
            {
              "originalPosition": 364,
              "body": "I don't think I had a convenience function before, but happy to add the convenience function here.\r\n",
              "createdAt": "2025-09-15T20:18:54Z",
              "updatedAt": "2025-09-15T20:18:54Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7ASx-f",
          "commit": {
            "abbreviatedOid": "376a5fa"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-15T20:19:35Z",
          "updatedAt": "2025-09-15T20:19:35Z",
          "comments": [
            {
              "originalPosition": 9,
              "body": "Ok, thanks - will give that a shot!",
              "createdAt": "2025-09-15T20:19:35Z",
              "updatedAt": "2025-09-15T20:19:35Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7AS5HS",
          "commit": {
            "abbreviatedOid": "376a5fa"
          },
          "author": "cjpatton",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-15T20:24:57Z",
          "updatedAt": "2025-09-15T20:24:57Z",
          "comments": [
            {
              "originalPosition": 364,
              "body": "I was thinking of `AppendElement`, which appears to \"allocate\" a variable for an element and \"set\" its value in one call. That is, if I'm reading correctly, the following are (morally) equivalent:\r\n\r\n```\r\n# Current ARC draft\r\nXVar = prover.AppendElement(\"X\", X)\r\n\r\n# Sigma draft\r\n[XVar] = statement.allocate_elements(1)\r\nstatement.set_elements([(XVar, X)])\r\n```",
              "createdAt": "2025-09-15T20:24:57Z",
              "updatedAt": "2025-09-15T20:57:10Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7AT4dv",
          "commit": {
            "abbreviatedOid": "376a5fa"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-15T21:51:02Z",
          "updatedAt": "2025-09-15T21:51:02Z",
          "comments": [
            {
              "originalPosition": 364,
              "body": "Oh I see, the current ARC `AppendElement` API is only there because we define the \"schnorr compiler\" ourselves, so that's our defined API.\r\n\r\nIn this PR, I'm trying to follow the Sigma draft spec as closely as possible, hence the two-step `allocate_elements` and then `set_elements`. I can make an `append_element` convenience function here too, but it seems to go against the spirit of using the sigma spec as directly as possible (or in other words, if we think an `append_element` convenience function is needed, maybe we should add that to the sigma spec itself, instead of at an outer layer?)",
              "createdAt": "2025-09-15T21:51:02Z",
              "updatedAt": "2025-09-15T21:51:02Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7AT5CQ",
          "commit": {
            "abbreviatedOid": "376a5fa"
          },
          "author": "cjpatton",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-15T21:52:19Z",
          "updatedAt": "2025-09-15T21:52:19Z",
          "comments": [
            {
              "originalPosition": 364,
              "body": "No need, it's sensible to keep things simple.",
              "createdAt": "2025-09-15T21:52:19Z",
              "updatedAt": "2025-09-15T21:52:19Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7AT5jy",
          "commit": {
            "abbreviatedOid": "376a5fa"
          },
          "author": "cjpatton",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-15T21:53:34Z",
          "updatedAt": "2025-09-15T21:53:35Z",
          "comments": [
            {
              "originalPosition": 9,
              "body": "Btw, use `?` instead of `!` if you want an informative reference.",
              "createdAt": "2025-09-15T21:53:35Z",
              "updatedAt": "2025-09-15T21:53:35Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7AUbBo",
          "commit": {
            "abbreviatedOid": "376a5fa"
          },
          "author": "cjpatton",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-15T23:15:46Z",
          "updatedAt": "2025-09-15T23:15:46Z",
          "comments": [
            {
              "originalPosition": 292,
              "body": "Oh, also: I believe we want `NISigmaProtocol(iv, statement)` rather than `NISigmaProtocol.init(iv, statement)`. Perhaps another swift thing?",
              "createdAt": "2025-09-15T23:15:46Z",
              "updatedAt": "2025-09-15T23:15:46Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7AWyT6",
          "commit": {
            "abbreviatedOid": "376a5fa"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-16T04:34:04Z",
          "updatedAt": "2025-09-16T04:34:04Z",
          "comments": [
            {
              "originalPosition": 292,
              "body": "Fixed, thanks for the catches!",
              "createdAt": "2025-09-16T04:34:04Z",
              "updatedAt": "2025-09-16T04:34:04Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7AW1zT",
          "commit": {
            "abbreviatedOid": "376a5fa"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-16T04:38:09Z",
          "updatedAt": "2025-09-16T04:38:09Z",
          "comments": [
            {
              "originalPosition": 257,
              "body": "Updated, thanks!",
              "createdAt": "2025-09-16T04:38:09Z",
              "updatedAt": "2025-09-16T04:38:09Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7AmbBf",
          "commit": {
            "abbreviatedOid": "0c1d73b"
          },
          "author": "cjpatton",
          "authorAssociation": "CONTRIBUTOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2025-09-16T19:00:45Z",
          "updatedAt": "2025-09-16T19:00:45Z",
          "comments": []
        },
        {
          "id": "PRR_kwDONyB6uM7A3SCg",
          "commit": {
            "abbreviatedOid": "7a783c8"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-17T18:29:11Z",
          "updatedAt": "2025-09-17T18:29:11Z",
          "comments": [
            {
              "originalPosition": 562,
              "body": "FYI - from discussion with Michele, he said that this is not the right way to make a prover... this is only initializing the factory class, but isn't specifying the ciphersuite.\r\n\r\nHe suggested the following instead:\r\n```\r\n    NIZK = CIPHERSUITE['sigma/Shake128+P256']\r\n    proof = NIZK(session_id, statement).prove(witness, rng)\r\n    print(f'Proof: {proof.hex()}')\r\n```\r\n\r\nHowever, this API doesn't actually exist in the sigma spec right now, it only exists in the sigma poc code... so we'd also need to add it to the sigma spec to be able to reference it. I'll add an issue to track that work on the sigma side.",
              "createdAt": "2025-09-17T18:29:11Z",
              "updatedAt": "2025-09-17T18:29:11Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7A3UTc",
          "commit": {
            "abbreviatedOid": "7a783c8"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-17T18:32:29Z",
          "updatedAt": "2025-09-17T18:32:29Z",
          "comments": [
            {
              "originalPosition": 562,
              "body": "Filed a sigma issue here: https://github.com/mmaker/draft-irtf-cfrg-sigma-protocols/issues/74\r\n",
              "createdAt": "2025-09-17T18:32:29Z",
              "updatedAt": "2025-09-17T18:32:29Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7A4R9X",
          "commit": {
            "abbreviatedOid": "7a783c8"
          },
          "author": "cjpatton",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-17T19:37:27Z",
          "updatedAt": "2025-09-17T19:37:27Z",
          "comments": [
            {
              "originalPosition": 562,
              "body": "fyi @armfazh, as this is relevant for https://github.com/SamuelSchlesinger/draft-act/pull/12",
              "createdAt": "2025-09-17T19:37:27Z",
              "updatedAt": "2025-09-17T19:37:28Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7CW4Sw",
          "commit": {
            "abbreviatedOid": "7a783c8"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-24T04:06:26Z",
          "updatedAt": "2025-09-24T04:06:27Z",
          "comments": [
            {
              "originalPosition": 562,
              "body": "Opened a PR to address that issue / add the NIZK class and instances:\r\nhttps://github.com/mmaker/draft-irtf-cfrg-sigma-protocols/pull/79",
              "createdAt": "2025-09-24T04:06:27Z",
              "updatedAt": "2025-09-24T04:06:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7mWaZa",
          "commit": {
            "abbreviatedOid": "79fa154"
          },
          "author": "armfazh",
          "authorAssociation": "CONTRIBUTOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2026-02-27T03:21:28Z",
          "updatedAt": "2026-02-27T03:21:28Z",
          "comments": []
        }
      ]
    },
    {
      "number": 38,
      "id": "PR_kwDONyB6uM6pDhqW",
      "title": "Adding range proofs for arbitrary ranges",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/38",
      "state": "MERGED",
      "author": "meyira",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Add range proofs for ranges within [0,max), where max is an arbitrary number.",
      "createdAt": "2025-09-17T11:34:57Z",
      "updatedAt": "2026-01-12T08:25:51Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "178815ff3601f65cb04edcef11f6b4b33d1f349d",
      "headRepository": "meyira/draft-arc",
      "headRefName": "main",
      "headRefOid": "8a90767dc9177d4825ac05ba4bba213212881b5a",
      "closedAt": "2026-01-12T08:25:51Z",
      "mergedAt": "2026-01-12T08:25:51Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "b92e4d3c6ac48fd59683b433145d84b29b1b5978"
      },
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "This looks good, but I'm worried that it will be easy to forget to have the verifier check that `C = sum_i (bases[i] * D[i])`, so I would like to either explicitly write out this check for the verifier to perform, or (to be more thorough), give an example of the full proof generation/verification for a range proof.",
          "createdAt": "2025-09-24T05:26:13Z",
          "updatedAt": "2025-09-24T05:26:13Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "We should also double check that this works with the new/changed NISigmaProtocol API. At a glance, it seems like yes because it only touches the constraint statements, but need to look more carefully.\r\nhttps://github.com/mmaker/draft-irtf-cfrg-sigma-protocols/pull/79",
          "createdAt": "2025-09-24T22:57:10Z",
          "updatedAt": "2025-09-28T22:03:13Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Also a note for reviewers, this corresponds (loosely) to the range proof implemented in `sigma-rs` here:\r\nhttps://github.com/mmaker/sigma-rs/blob/main/src/tests/test_relations.rs#L204\r\n\r\nI say \"loosely\" because `sigma-rs` doesn't follow the sigma spec API exactly, and has a few helpers/shortcuts, such as for checking relations outside the proof. This is relevant for the check of `C = sum_i (bases[i] * D[i])` in this case.",
          "createdAt": "2025-09-25T18:04:19Z",
          "updatedAt": "2025-09-25T18:04:19Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "I discussed this with @chris-wood  to get him up to speed, and will copy some notes here in case it is helpful for others to understand the range proof construction. This has overlap with Lena's existing explanation in the spec documentation.\r\n\r\nA power-of-two bit-decomposition range proof works as follows:\r\nYou want to prove that v is in [0, 2^n) where you are given V = Commit(v) = v*G + r*H\r\n1. \"we can bit decompose v into n bits\": v = sum_(i=0^(2^n)) (b_i * 2^i). The easiest way to do this is by making the commitments to b_i be an \"additive secret share\" (so to speak) of V. In other words, choose the blinding factors `s_i` of D_i = Commit(b_i) = b_i * G + s_i * H such that sum_i(s_i) = r. Then, V = sum_i(D_i * 2^i) because commitments are additively homomorphic. This can be checked by the verifier outside the circuit.\r\n2. \"each bit is actually a bit: b_i in {0, 1}\": you can do this multiple ways: \r\n2a. through multiplication: (b_i) * (b_i - 1) = 0\r\n2b. through \"additive linear constraints\":\r\n       first commit to b_i : b_i: D_i = b_i * G + s_i * H\r\n       then constrain b_i to be 0 or 1: b_i: D_i = b_i * D_i + s2_i * H\r\n       how this works: if b_i = 0, set s2_i to equal s_i and the constraint holds\r\n                                  if b_i = 1, set s2_i to 0 and the constraint holds\r\n                                  if b_i is any other value, you have to break DL for the constraint to hold\r\nWatson explained this briefly on the cfrg list: https://mailarchive.ietf.org/arch/msg/cfrg/LKV8qVYnpMUwnfeWwGz90tzTcS8/\r\nAnd Ian expanded on it here: https://mailarchive.ietf.org/arch/msg/cfrg/J1M45Kqr5JsbH7IBa0Q_WvEmdM0/\r\nFor this approach, we choose the 2b route because then we can avoid OR statements in the proof system (which add complexity).\r\n\r\nThe last step is expanding this to non-power-of-two ranges, which requires a strategic choice of bases.\r\nIn short, the first n-1 bases will be powers of to (2^i), and the last base will be the \"remainder\" between what can be represented by the first n-1 bases, and the final range we want to prove.\r\nI'm being a bit hand-wavy here, I think Jonathan Katz explained this somewhere in the CFRG mailing list but I'm having trouble finding that message. Will link it if I find it.\r\n\r\nI summarize this approach in the cfrg mailing list here:\r\nhttps://mailarchive.ietf.org/arch/msg/cfrg/nor_Mx8PsBeiyUcQDR6Ax_ozqN0/",
          "createdAt": "2025-09-25T19:08:10Z",
          "updatedAt": "2025-09-25T19:08:10Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks for the feedback, jkatz! This looks good, with the exception that the Sigma / F-S API has changed in the meantime and now the `allocate_scalar` functions (and a few others) have changed in how they need to be called.\r\n\r\nI can take a pass on updating this PR to be in line with those changes. \r\nIn the meantime @chris-wood can you review this?",
          "createdAt": "2025-10-07T22:08:19Z",
          "updatedAt": "2025-10-07T22:08:19Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Currently, the range proof addition is \"free floating\" as it is not called by the ARC spec.\r\n\r\nWill merge this in, to unblock progress on defining nonce hiding in the ARC spec.\r\nAs for the matching reference implementation, we can do that along with the nonce hiding changes.\r\n",
          "createdAt": "2026-01-12T07:32:53Z",
          "updatedAt": "2026-01-12T07:32:53Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7DgcM9",
          "commit": {
            "abbreviatedOid": "8c0c0da"
          },
          "author": "jkatz2",
          "authorAssociation": "NONE",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-29T14:08:32Z",
          "updatedAt": "2025-09-29T14:08:33Z",
          "comments": [
            {
              "originalPosition": 61,
              "body": "I don't think this is necessary -- the remainder can never be 0",
              "createdAt": "2025-09-29T14:08:33Z",
              "updatedAt": "2025-09-29T14:08:33Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7DiVTH",
          "commit": {
            "abbreviatedOid": "8c0c0da"
          },
          "author": "jkatz2",
          "authorAssociation": "NONE",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-29T15:44:12Z",
          "updatedAt": "2025-09-29T15:44:12Z",
          "comments": [
            {
              "originalPosition": 128,
              "body": "Don't you need r = \\sum_i s[i] * bases[i]? (Right now you have r = \\sum_i s[i].)",
              "createdAt": "2025-09-29T15:44:12Z",
              "updatedAt": "2025-09-29T15:44:12Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7DipqF",
          "commit": {
            "abbreviatedOid": "8c0c0da"
          },
          "author": "cjpatton",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-29T16:04:50Z",
          "updatedAt": "2025-09-29T16:04:55Z",
          "comments": [
            {
              "originalPosition": 61,
              "body": "I believe the remainder will be non-zero if `upper_bound` is not a power of two?",
              "createdAt": "2025-09-29T16:04:50Z",
              "updatedAt": "2025-09-29T16:04:55Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7Di18c",
          "commit": {
            "abbreviatedOid": "8c0c0da"
          },
          "author": "jkatz2",
          "authorAssociation": "NONE",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-29T16:16:30Z",
          "updatedAt": "2025-09-29T16:16:31Z",
          "comments": [
            {
              "originalPosition": 61,
              "body": "Yes, and also when it is a power of two.",
              "createdAt": "2025-09-29T16:16:31Z",
              "updatedAt": "2025-09-29T16:16:31Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7Di3ez",
          "commit": {
            "abbreviatedOid": "8c0c0da"
          },
          "author": "cjpatton",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-29T16:18:04Z",
          "updatedAt": "2025-09-29T16:18:04Z",
          "comments": [
            {
              "originalPosition": 61,
              "body": "ah, so your point is that we don't need the `if` statement because we will always execute it?",
              "createdAt": "2025-09-29T16:18:04Z",
              "updatedAt": "2025-09-29T16:18:04Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7DjtUG",
          "commit": {
            "abbreviatedOid": "8c0c0da"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-29T17:22:38Z",
          "updatedAt": "2025-09-29T17:22:38Z",
          "comments": [
            {
              "originalPosition": 61,
              "body": "Right, IIUC if `upper_bound` is a power of two, then `remainder` will simply be the next power of two. Eg if `upper_bound` = 16, bases without remainder = [1, 2, 4] and the remainder will be [8].",
              "createdAt": "2025-09-29T17:22:38Z",
              "updatedAt": "2025-09-29T17:22:38Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7DjvXl",
          "commit": {
            "abbreviatedOid": "8c0c0da"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-29T17:25:27Z",
          "updatedAt": "2025-09-29T17:25:27Z",
          "comments": [
            {
              "originalPosition": 128,
              "body": "Yes, exactly - good catch. That's what is implemented in the rust library:\r\nhttps://github.com/sigma-rs/sigma-proofs/blob/main/src/tests/test_relations.rs#L279\r\n```\r\n    let partial_sum = (1..bases.len())\r\n        .map(|i| G::Scalar::from(bases[i]) * s[i])\r\n        .sum::<G::Scalar>();\r\n    s[0] = r - partial_sum;\r\n```",
              "createdAt": "2025-09-29T17:25:27Z",
              "updatedAt": "2025-09-29T17:25:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7DwCmt",
          "commit": {
            "abbreviatedOid": "8c0c0da"
          },
          "author": "meyira",
          "authorAssociation": "NONE",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-30T11:24:05Z",
          "updatedAt": "2025-09-30T11:24:05Z",
          "comments": [
            {
              "originalPosition": 61,
              "body": "changed to remove if statement in 8a90767",
              "createdAt": "2025-09-30T11:24:05Z",
              "updatedAt": "2025-09-30T11:24:05Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7DwCz-",
          "commit": {
            "abbreviatedOid": "8c0c0da"
          },
          "author": "meyira",
          "authorAssociation": "NONE",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2025-09-30T11:24:18Z",
          "updatedAt": "2025-09-30T11:24:18Z",
          "comments": [
            {
              "originalPosition": 128,
              "body": "added base multiplication in 8a90767",
              "createdAt": "2025-09-30T11:24:18Z",
              "updatedAt": "2025-09-30T11:24:18Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7ZhlEh",
          "commit": {
            "abbreviatedOid": "8a90767"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2026-01-12T07:33:17Z",
          "updatedAt": "2026-01-12T07:33:17Z",
          "comments": []
        }
      ]
    },
    {
      "number": 39,
      "id": "PR_kwDONyB6uM6uGbfz",
      "title": "Explicitly encode field lengths in contexts",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/39",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #25 ",
      "createdAt": "2025-10-16T14:26:39Z",
      "updatedAt": "2025-10-17T22:06:44Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "4ddb1eb4c069c9474b67c6abc7bc245bd68a239e",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "caw/explicit-length-encoding",
      "headRefOid": "1a1680a46c14b96b2a5bd70577c59dd08cdb4742",
      "closedAt": "2025-10-17T22:06:39Z",
      "mergedAt": "2025-10-17T22:06:39Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "3977f5860105309e6126266b3b7cd4c18bbc255c"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7Hz4Cb",
          "commit": {
            "abbreviatedOid": "f211f6b"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "\ud83d\udc4d ",
          "createdAt": "2025-10-17T22:02:33Z",
          "updatedAt": "2025-10-17T22:02:33Z",
          "comments": []
        }
      ]
    },
    {
      "number": 40,
      "id": "PR_kwDONyB6uM6uGjFP",
      "title": "Align on credential being the primary noun (instead of tokens) for issuance",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/40",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #23 ",
      "createdAt": "2025-10-16T14:34:59Z",
      "updatedAt": "2025-10-17T22:46:05Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "3977f5860105309e6126266b3b7cd4c18bbc255c",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "caw/align-on-credentials",
      "headRefOid": "90af5a10a74c65dadc62ca5c763dd190cabd9655",
      "closedAt": "2025-10-17T22:46:01Z",
      "mergedAt": "2025-10-17T22:46:01Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "83226bde90dae15086315c5140176485acf23bf8"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7Hz6Nn",
          "commit": {
            "abbreviatedOid": "90af5a1"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "This lines up better with how we should think about ARC issuance! Thanks for the updates",
          "createdAt": "2025-10-17T22:07:56Z",
          "updatedAt": "2025-10-17T22:45:55Z",
          "comments": [
            {
              "originalPosition": 131,
              "body": "What's the purpose of this section?",
              "createdAt": "2025-10-17T22:07:56Z",
              "updatedAt": "2025-10-17T22:45:55Z"
            },
            {
              "originalPosition": 131,
              "body": "Ah I found an RFC for media types which also explains what they're for :)\r\nhttps://datatracker.ietf.org/doc/html/rfc6838",
              "createdAt": "2025-10-17T22:45:07Z",
              "updatedAt": "2025-10-17T22:45:55Z"
            }
          ]
        }
      ]
    },
    {
      "number": 41,
      "id": "PR_kwDONyB6uM6uGlpW",
      "title": "4 octets instead of 32 bits",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/41",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Close #17 \r\n\r\n`challenge_digest` is already defined in that section (as below), so I didn't change anything there.\r\n\r\n```\r\n\"challenge_digest\" is a 32-octet value containing the hash of the original TokenChallenge, SHA-256(TokenChallenge).\r\n```",
      "createdAt": "2025-10-16T14:37:37Z",
      "updatedAt": "2025-10-17T19:58:02Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "24dac6275c1660a973e03a584fbe07733f54a5a8",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "caw/bits-to-bytes",
      "headRefOid": "5b19e526e166c384faacf0f8c3331babd5824d75",
      "closedAt": "2025-10-17T19:57:59Z",
      "mergedAt": "2025-10-17T19:57:58Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "4ddb1eb4c069c9474b67c6abc7bc245bd68a239e"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7HyKfa",
          "commit": {
            "abbreviatedOid": "5b19e52"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "\ud83d\udc4d ",
          "createdAt": "2025-10-17T19:57:53Z",
          "updatedAt": "2025-10-17T19:57:53Z",
          "comments": []
        }
      ]
    },
    {
      "number": 42,
      "id": "PR_kwDONyB6uM6uGuyW",
      "title": "Output a tag from VerifyPresentation",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/42",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #29 ",
      "createdAt": "2025-10-16T14:47:33Z",
      "updatedAt": "2025-10-17T19:58:25Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "24dac6275c1660a973e03a584fbe07733f54a5a8",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "caw/output-tag",
      "headRefOid": "e683f380e94a7fc9507f9a8c3ea9d537b9b19113",
      "closedAt": "2025-10-17T19:57:01Z",
      "mergedAt": "2025-10-17T19:57:01Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "bd4fbf264149899a8b39972bbe45876afd9559a3"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7HyJtR",
          "commit": {
            "abbreviatedOid": "e683f38"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM",
          "createdAt": "2025-10-17T19:56:46Z",
          "updatedAt": "2025-10-17T19:56:46Z",
          "comments": []
        }
      ]
    },
    {
      "number": 43,
      "id": "PR_kwDONyB6uM6usgCs",
      "title": "Rename `cfrg` spec to `privacypass-crypto`",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/43",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "- Rename `cfrg` spec to `privacypass-crypto`, to reflect that the call for adoption is happening in the Privacy Pass working group (both for the Privacy Pass issuance workflow, and for the crypto protocol).\r\n- Update internal names and links\r\n- Also sneak in a typo fix for the RandomScalar range, to start at 1 instead of 0.\r\n\r\nNote that the privacypass spec does not yet reference the updated name for the crypto spec, because we need to publish that first before updating the privacypass spec reference (or else the build breaks). Will do that as a fast-follow.",
      "createdAt": "2025-10-20T19:20:44Z",
      "updatedAt": "2025-10-20T19:22:38Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "83226bde90dae15086315c5140176485acf23bf8",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "cathie/ietf124-cleanup",
      "headRefOid": "d7e0b7251b1a53fccb0cfe5d29b7e465e1aaf62a",
      "closedAt": "2025-10-20T19:22:35Z",
      "mergedAt": "2025-10-20T19:22:35Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "92eb423bdb0b7275bf97c33219f2c9c2d0aef7f6"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7IIXlR",
          "commit": {
            "abbreviatedOid": "d7e0b72"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2025-10-20T19:22:16Z",
          "updatedAt": "2025-10-20T19:22:16Z",
          "comments": []
        }
      ]
    },
    {
      "number": 44,
      "id": "PR_kwDONyB6uM6usozP",
      "title": "Update ARC crypto reference",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/44",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Update ARC crypto reference from `cfrg` to `privacypass-crypto`.\r\n\r\nWe couldn't do this in the previous PR because we had not yet pushed the `privacypass-crypto` spec to Datatracker, so making this change would have broken the spec build.",
      "createdAt": "2025-10-20T19:34:03Z",
      "updatedAt": "2025-10-20T19:37:15Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "92eb423bdb0b7275bf97c33219f2c9c2d0aef7f6",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "cathie/privacypass-ref",
      "headRefOid": "357c7260dd68c1e208a2df90a7c483f486f17563",
      "closedAt": "2025-10-20T19:37:05Z",
      "mergedAt": "2025-10-20T19:37:05Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "e77336a8ba75a3f5b02d1fb68d2d9694921c8005"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7IIgSH",
          "commit": {
            "abbreviatedOid": "357c726"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2025-10-20T19:34:36Z",
          "updatedAt": "2025-10-20T19:34:36Z",
          "comments": []
        }
      ]
    },
    {
      "number": 45,
      "id": "PR_kwDONyB6uM6vQaIW",
      "title": "Update diagram to have credential finalisation and presentation",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/45",
      "state": "MERGED",
      "author": "thibmeu",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Here is the updated diagram\r\n\r\n![credentials](https://github.com/user-attachments/assets/6d97510b-30ac-4e97-a58b-47766ca295eb)\r\n",
      "createdAt": "2025-10-23T12:35:18Z",
      "updatedAt": "2026-01-12T06:49:37Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "e77336a8ba75a3f5b02d1fb68d2d9694921c8005",
      "headRepository": "thibmeu/draft-arc",
      "headRefName": "main",
      "headRefOid": "c1807f2a5b2b1e126c00800339f863d044ddafdc",
      "closedAt": "2026-01-12T06:49:37Z",
      "mergedAt": "2026-01-12T06:49:37Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "178815ff3601f65cb04edcef11f6b4b33d1f349d"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 48,
      "id": "PR_kwDONyB6uM68CJvA",
      "title": "Add nonce hiding with range proofs",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/48",
      "state": "CLOSED",
      "author": "mike-marcacci",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "This proposes a change to the spec that address one of the open issues in the current draft:\r\n\r\n> OPEN ISSUE: hide the nonce and replace the tag proof with a range proof built from something like Bulletproofs.\r\n\r\nThis change:\r\n\r\n- Hides the nonce value in a Pedersen commitment (nonceCommit)\r\n- Uses Bulletproofs to prove nonce is in \\[0, presentationLimit)\r\n\r\n---\r\n\r\nI began working on this as a prerequisite for #47, and through it discovered that my use-case isn't a great fit for ARC on some deeper levels. (I'll close out that issue shortly.)\r\n\r\nI figured my sunk effort might as well go to good use, so I finished up this PR.\r\n\r\nDisclaimer: I am *not* a cryptographer, and needed to do a LOT of reading to assemble this. Every line of this is my work, but I used lots and lots of AI to answer questions, to make sure I understood the concepts thoroughly, and to find flaws in each of my many attempts at this \u2013 so don't let a lack of superficial mistakes hide any fundamental flaws that I may have made.\r\n\r\nThat said, I am reasonably confident in this and happy to walk through it on a call if anyone would find that helpful.\r\n\r\n",
      "createdAt": "2026-01-08T04:37:35Z",
      "updatedAt": "2026-01-12T23:31:12Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "e77336a8ba75a3f5b02d1fb68d2d9694921c8005",
      "headRepository": "mike-marcacci/draft-arc",
      "headRefName": "nonce-hiding",
      "headRefOid": "a7dd5818de28fe37bb377d6c0b3a5ea33f4cdb47",
      "closedAt": "2026-01-12T06:51:04Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks for your contribution! I'm taking a look now.\r\nSorry for missing your issue https://github.com/chris-wood/draft-arc/issues/47 until now - I've left some comments there as well, in case it helps.",
          "createdAt": "2026-01-12T06:22:22Z",
          "updatedAt": "2026-01-12T06:22:22Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "This is very helpful, but one problem with this approach is that bulletproofs has not been specified in a standard yet. In order to use it in an IETF spec, we either have to specify it in the ARC spec itself, or call into an existing specification.\r\n\r\nUsing sigma proofs is less efficient (due to the lack of compression from the Bulletproofs inner product), but for our purposes it is preferable to use something that is adopted as a standard. It also has less complexity than Bulletproofs.\r\nhttps://datatracker.ietf.org/doc/draft-irtf-cfrg-sigma-protocols/\r\nWe are working on defining a range proof using sigma protocols here:\r\nhttps://github.com/chris-wood/draft-arc/pull/38\r\n\r\nSo I'll close this PR, as it doesn't take the approach that we think is best for standardization purposes. Thanks for your contribution though!",
          "createdAt": "2026-01-12T06:51:04Z",
          "updatedAt": "2026-01-12T06:51:04Z"
        },
        {
          "author": "mike-marcacci",
          "authorAssociation": "NONE",
          "body": "Thanks for the review @cathieyun! Using sigma proofs makes far more sense given the work being done to formalize it.",
          "createdAt": "2026-01-12T23:31:11Z",
          "updatedAt": "2026-01-12T23:31:11Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7Y0bIe",
          "commit": {
            "abbreviatedOid": "a7dd581"
          },
          "author": "mike-marcacci",
          "authorAssociation": "NONE",
          "state": "COMMENTED",
          "body": "At one point I had much more normative text on Bulletproofs themselves. However, I felt that cluttered this spec, introduced more opportunities for mistakes, and ultimately was unnecessary.\r\n\r\nInstead I used the interface of popular libraries as the cutoff for omitting \"internal\" details.\r\n\r\nThe Bulletproofs paper is _not_ a normative spec, so this might not be an acceptable approach.",
          "createdAt": "2026-01-08T04:40:49Z",
          "updatedAt": "2026-01-08T17:56:23Z",
          "comments": [
            {
              "originalPosition": 190,
              "body": "This might not be appropriate for a spec since the statements are already unambiguously defined. However, I needed this written out to easily follow the logic as I iterated, and thought it was helpful to keep.\r\n\r\nIf it stays, it needs to be vetted for perfect accuracy.",
              "createdAt": "2026-01-08T04:40:49Z",
              "updatedAt": "2026-01-08T05:23:37Z"
            },
            {
              "originalPosition": 343,
              "body": "The >=, < colloquialisms can probably be omitted, but I started off thinking in these terms.\r\n\r\n`nonce \u2208 [0, 2^n)` is in fact stricter than `nonce >= 0`, so this holds true but might add more potential for confusion than it clarifies.",
              "createdAt": "2026-01-08T04:43:22Z",
              "updatedAt": "2026-01-08T05:24:10Z"
            },
            {
              "originalPosition": 361,
              "body": "I chose u32 for `presentationLimit` because the nonce is already constrained as:\n\nhttps://github.com/chris-wood/draft-arc/blob/e77336a8ba75a3f5b02d1fb68d2d9694921c8005/draft-yun-privacypass-arc.md?plain=1#L403",
              "createdAt": "2026-01-08T04:46:08Z",
              "updatedAt": "2026-01-08T05:11:36Z"
            },
            {
              "originalPosition": 375,
              "body": "I borrowed the naming conventions directly from [the rust implementation's RangeProof](https://github.com/dalek-cryptography/bulletproofs/blob/be67b6d5f5ad1c1f54d5511b52e6d645a1313d07/src/range_proof/mod.rs#L60-L75).",
              "createdAt": "2026-01-08T04:48:54Z",
              "updatedAt": "2026-01-08T05:11:36Z"
            },
            {
              "originalPosition": 381,
              "body": "And similarly from [the rust implementation's InnerProductProof](https://github.com/dalek-cryptography/bulletproofs/blob/be67b6d5f5ad1c1f54d5511b52e6d645a1313d07/src/inner_product_proof.rs#L20-L23).",
              "createdAt": "2026-01-08T04:49:40Z",
              "updatedAt": "2026-01-08T05:11:36Z"
            },
            {
              "originalPosition": 389,
              "body": "I left size calculations parameterized all the way up to make them more traceable, but we could simply put this, since both m and n (and therefore k) are static.",
              "createdAt": "2026-01-08T04:51:36Z",
              "updatedAt": "2026-01-08T05:25:31Z"
            },
            {
              "originalPosition": 56,
              "body": "The dependance on `nonceCommit` by both proofs ensures that the same value of nonce is used, even though the presentationProof does not bind the range proof.",
              "createdAt": "2026-01-08T04:54:11Z",
              "updatedAt": "2026-01-08T05:11:36Z"
            },
            {
              "originalPosition": 511,
              "body": "This roughly follows the [verify_multiple signature](https://doc.dalek.rs/bulletproofs/struct.RangeProof.html#method.verify_multiple) in the rust implementation.",
              "createdAt": "2026-01-08T04:58:27Z",
              "updatedAt": "2026-01-08T05:11:36Z"
            },
            {
              "originalPosition": 448,
              "body": "This roughly follows the [prove_multiple signature](https://doc.dalek.rs/bulletproofs/struct.RangeProof.html#method.prove_multiple) in the rust implementation.",
              "createdAt": "2026-01-08T04:58:51Z",
              "updatedAt": "2026-01-08T05:11:36Z"
            },
            {
              "originalPosition": 554,
              "body": "We should probably consider the susceptibility of this proposal to quantum threats.\r\n\r\nIn [the IETF 124 video](https://www.youtube.com/watch?v=3ncPvxEUMUA&t=2617s) @cathieyun noted that ARC's current PQ status is:\r\n- Unlinkability between issuance and presentation is preserved\r\n- Unlinkability between two presentations is broken\r\n\r\nBinding/unforgeability is entirely broken of course, but less concerning as this doesn't open \"store now decrypt later\" vulnerabilities.\r\n\r\nIt's my understanding that bulletproofs are in isolation still perfectly hiding (Pedersen commitments), but I haven't walked through the ramifications of their introduction on ARC as a whole.",
              "createdAt": "2026-01-08T05:03:59Z",
              "updatedAt": "2026-01-08T05:26:54Z"
            }
          ]
        }
      ]
    },
    {
      "number": 50,
      "id": "PR_kwDONyB6uM6-Xp7n",
      "title": "Update draft names to reflect adoption",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/50",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Now that ARC has been adopted by privacy pass, this PR updates the draft names and pointers to privacy pass working group (as opposed to `yun-...`). It also updates some links to reflect that the repo has moved to the `ietf-wg-privacypass` working group.\r\n\r\nAfter this change, I will need to push updated tags to datatracker with the new names. Then, I will open another PR to update the datatracker and ID links to the new datatracker links.",
      "createdAt": "2026-01-21T05:46:18Z",
      "updatedAt": "2026-01-23T21:09:55Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "778792362b04b13ff283db6caf245f6f7f453ecb",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "adoption-update",
      "headRefOid": "4f2347fabc2a32e3c72535ca198c31e418600067",
      "closedAt": "2026-01-23T20:14:05Z",
      "mergedAt": "2026-01-23T20:14:05Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "0a48cfdd6c81ac194e80957c9d1d6f74239acb70"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 51,
      "id": "PR_kwDONyB6uM6_SeLp",
      "title": "Update datatracker links to point to privacypass-arc-crypto",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/51",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Now that we have added the `draft-privacypass-arc-crypto-00` tag, we have a datatracker ID to point to!\r\nThis updates the links to point to the right place.\r\nThere should no longer be any mention of `draft-yun-*` named drafts now.",
      "createdAt": "2026-01-26T04:11:40Z",
      "updatedAt": "2026-01-26T14:57:34Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "0a48cfdd6c81ac194e80957c9d1d6f74239acb70",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "update-links",
      "headRefOid": "614d8c8e3ad0a7a9f3a5970d725191f33b3f3550",
      "closedAt": "2026-01-26T14:57:34Z",
      "mergedAt": "2026-01-26T14:57:34Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "565b8f63f17b8889fb169b1e9536b062059dec99"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7c65Ak",
          "commit": {
            "abbreviatedOid": "614d8c8"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2026-01-26T14:57:29Z",
          "updatedAt": "2026-01-26T14:57:29Z",
          "comments": []
        }
      ]
    },
    {
      "number": 52,
      "id": "PR_kwDONyB6uM6_Sekl",
      "title": "Add Armando to coauthors list",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/52",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Adding Armando, as he has been contributing to and implementing the ARC spec!",
      "createdAt": "2026-01-26T04:12:40Z",
      "updatedAt": "2026-01-26T16:21:48Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "0a48cfdd6c81ac194e80957c9d1d6f74239acb70",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "add-coauthor",
      "headRefOid": "640a7816d98c8baf4dc50eb92d88ac8e3e9ec767",
      "closedAt": "2026-01-26T14:57:17Z",
      "mergedAt": "2026-01-26T14:57:17Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "17c811039fb94221a3df73805b645a4148aa755b"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7c64sH",
          "commit": {
            "abbreviatedOid": "640a781"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2026-01-26T14:57:12Z",
          "updatedAt": "2026-01-26T14:57:12Z",
          "comments": []
        }
      ]
    },
    {
      "number": 53,
      "id": "PR_kwDONyB6uM6_UCOy",
      "title": "Update spec to hide nonces using a range proof",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/53",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "cathieyun"
      ],
      "labels": [],
      "body": "This PR adds a range proof to the ARC Presentation, in order to hide the nonce.\r\nPreviously, the nonce had to be sent to the verifier, and the verifier would check that the nonce was in range. That resulted in interesting privacy implications - for instance, if a verifier received two presentations with the same nonce, it would know that they came from different credentials.\r\n\r\nRange proof overhead, in terms of `k = ceil(log2(presentationLimit))`:\r\n- Size: adds k * (1 group element and 3 scalars) = k * (33 + 3*32) = k * 129 bytes\r\n- Computation: O(k) elliptic curve operations for prover and verifier. \r\n  - For the prover, that's 2*k EC multiplications, with a handful of scalar operations.\r\n  - For the verifier, that's ~ 4*k EC multiplications, with a handful of scalar operations (checking 2 constraints per bit, where each constraint requires 2 EC multiplications).\r\n\r\nConcrete size increase examples:\r\n ``` \r\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n  \u2502 Presentation Limit \u2502 k (bits) \u2502 Range Proof Size \u2502 Total Presentation \u2502 % Increase \u2502\r\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n  \u2502 2                  \u2502 1        \u2502 129 bytes        \u2502 354 bytes          \u2502 ~57%       \u2502\r\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n  \u2502 8                  \u2502 3        \u2502 387 bytes        \u2502 612 bytes          \u2502 ~172%      \u2502\r\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n  \u2502 16                 \u2502 4        \u2502 516 bytes        \u2502 741 bytes          \u2502 ~229%      \u2502\r\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n  \u2502 32                 \u2502 5        \u2502 645 bytes        \u2502 870 bytes          \u2502 ~287%      \u2502\r\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n  \u2502 100                \u2502 7        \u2502 903 bytes        \u2502 1,128 bytes        \u2502 ~401%      \u2502\r\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n  \u2502 1000               \u2502 10       \u2502 1,290 bytes      \u2502 1,515 bytes        \u2502 ~573%      \u2502\r\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nSpec tasks\r\n- [x] Define `MakeRangeProof` function from `ComputeStatementAndWitnesses`\r\n- [x] Define `VerifyRangeProof` function from `ComputeStatementAndWitnesses`\r\n- [x] Update `ComputeStatementAndWitnesses` to use the same terminology as the rest of the draft (eg nonce, nonceBlinding, nonceCommit, presentationLimit) -\r\n   - actually I just removed the `ComputeStatementAndWitnesses` function altogether, in favor of computing the statement and witnesses in `MakeRangeProof` and `VerifyRangeProof` directly.\r\n- [x] Credit Lena for Range Proof work\r\n- [x] Update `MakeRangeProof` and `VerifyRangeProof` to be \"proof helpers\", so they add variables and constraints to the statement but don't generate the proof itself. That way, the range proof can be part of the presentation proof.\r\n\r\nCode (poc) tasks\r\n- [x] Implement the range proof in the proof of concept code\r\n- [x] Add tests for range proof\r\n- [x] Update ARC proof of concept code to be in line with these spec changes.\r\n- [x] Add negative tests for ARC (failure cases)\r\n\r\nCleanup / refactor work\r\n- [x] move the `D` vector from Presentation to PresentationProof, since it's technically a part of the proof, not the presentation itself.\r\n- [x] rebased off of `main` to pull in spec renaming changes \r\n\r\n------------------\r\nDiscussion: separate range proof for Presentation?\r\nSlack thread here: https://ietf.slack.com/archives/C09ASPV0C49/p1769196560907949?thread_ts=1769196164.769419&cid=C09ASPV0C49\r\nFor nonce hiding, we are adding a range proof to prove that the nonce is within the rate limit. I can either send this as a separate proof in addition to the presentation proof, or smash both of those into one big proof.\r\n1. In favor of combining: only one proof to verify (harder to \"forget\" to verify one), you save one scalar element (the challenge). Also this is better practice for future development - if we want to add more properties to the ZKP, we want to add those as additional constraints, not make a new ZKP for each new property.\r\n2. In favor of keeping separate: makes it easier to treat the range proof as its own \"modular\" proof, increased clarity. For instance if someone was to just implement a standalone range proof verifier, you could just send the range proof to that verifier and it would work. It feels neater?\r\n- This PR takes the first approach, since it is better practice for future anonymous credentials development.",
      "createdAt": "2026-01-26T08:14:20Z",
      "updatedAt": "2026-02-21T22:57:26Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "940715dfd721b070cadc7bd6bccd9fc1d0874c0e",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "nonce-hiding",
      "headRefOid": "dc3806022ddf20f16c004cd0fce8b31eecde44b4",
      "closedAt": "2026-02-21T22:57:20Z",
      "mergedAt": "2026-02-21T22:57:20Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "365257fc6f68c12130e9f8e0a1d209c325781297"
      },
      "comments": [
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "Addressed Armando's previous round of feedback!\r\nWill wait for @chris-wood to review as well.",
          "createdAt": "2026-02-11T07:28:59Z",
          "updatedAt": "2026-02-11T07:28:59Z"
        },
        {
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "body": "I'll add the cost of the range proof (re bandwidth and computational cost) to the PR description. The bandwidth/size overhead is already listed in the PresentationProof size calculation.",
          "createdAt": "2026-02-21T22:47:43Z",
          "updatedAt": "2026-02-21T22:47:43Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7gCjTX",
          "commit": {
            "abbreviatedOid": "ac02dfa"
          },
          "author": "armfazh",
          "authorAssociation": "CONTRIBUTOR",
          "state": "CHANGES_REQUESTED",
          "body": "I did a pass on the spec document, in the next review cycle I will check the code. ",
          "createdAt": "2026-02-05T18:41:03Z",
          "updatedAt": "2026-02-05T19:32:22Z",
          "comments": [
            {
              "originalPosition": 93,
              "body": "moving this line right before the end of all computation, so it does not get into a bad state when an error happens later.\n",
              "createdAt": "2026-02-05T18:41:03Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 142,
              "body": "let's define this quantity somewhere, e.g. `LOG2_LIMIT = ceil(log2(presentationLimit))`",
              "createdAt": "2026-02-05T18:42:22Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 267,
              "body": "```suggestion\n4. T = m1 * tag + nonce * tag, where T = G.HashToGroup(presentationContext, \"Tag\")\n```",
              "createdAt": "2026-02-05T18:45:22Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 269,
              "body": "```suggestion\n5. constraints added by the range proof. See {#range-proof}.\n```",
              "createdAt": "2026-02-05T18:45:51Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 298,
              "body": "```suggestion\n  - response: [Scalar], an array of scalars for all variables (presentation + range proof)\n```",
              "createdAt": "2026-02-05T18:47:41Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 332,
              "body": "```suggestion\n  # 4. T = m1 * tag + nonce * tag, where T = G.HashToGroup(presentationContext, \"Tag\")\n```",
              "createdAt": "2026-02-05T18:49:30Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 370,
              "body": "```suggestion\n    - response: [Scalar], an array of scalars for all variables (presentation + range proof)\n```",
              "createdAt": "2026-02-05T18:50:20Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 438,
              "body": "```suggestion\npower of two, that is, `presentationLimit = 2^k` for some integer `k > 0`.\n```",
              "createdAt": "2026-02-05T18:53:13Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 453,
              "body": "```suggestion\n1. Commit to the bits of `nonce`. That is, for each bit `b[i]` of the k-bit decomposition of `nonce`,\n```",
              "createdAt": "2026-02-05T18:56:09Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 458,
              "body": "```suggestion\n`D[i] = b[i] * D[i] + s2[i] * generatorH` to the equation system. A valid witness `s2[i]` can only\n```",
              "createdAt": "2026-02-05T18:57:07Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 458,
              "body": "we have to mention here how `s2[i]` is computed from `b[i]`",
              "createdAt": "2026-02-05T18:58:06Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 462,
              "body": "```suggestion\n3. In addition to verify the proof of the above relation, the verifier checks that the sum of the bit\n```",
              "createdAt": "2026-02-05T18:58:48Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 467,
              "body": "```suggestion\nnonceCommit = D[0] * 2^0 + D[1] * 2^1 + D[2] * 2^2 + ... + D[k-1] * 2^{k-1}\n```",
              "createdAt": "2026-02-05T18:59:15Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 519,
              "body": "It seems that the `presentatioLimit` is representable.\nAlso we may want to add a comment about whether we enforce cannonical representatives or being flexible to use an alternative representation.\n\n---\n\npresentationLimit = 17\ni:          1,  2,  4, 8\nremainder: 16, 14, 10, 2 \nbases =     1,  2,  4, 8, 2\nsorted = [8, 4, 2, 2, 1]\n\n| value | ComputeBases Repr| Alternative Repr|\n|--|--|--|\n| 0  | 0,0,0,0,0 | - |\n| 1  | 0,0,0,0,1 | - |\n| 2  | 0,0,1,0,0 | 0,0,0,1,0 |\n| 3  | 0,0,1,0,1 | 0,0,0,1,1 |\n| 4  | 0,1,0,0,0 | 0,0,1,1,0 |\n| 5  | 0,1,0,0,1 | 0,0,1,0,1 |\n| 6  | 0,1,1,0,0 | 0,1,0,1,0 |\n| 7  | 0,1,1,0,1 | 0,1,0,1,1 |\n| 8  | 1,0,0,0,0 | 0,1,1,1,0 |\n| 9  | 1,0,0,0,1 | 0,1,1,1,1 |\n| 10 | 1,0,1,0,0 | 1,0,0,1,0 |\n| 11 | 1,0,1,0,1 | 1,0,0,1,1 |\n| 12 | 1,1,0,0,0 | 1,0,1,1,0 |\n| 13 | 1,1,0,0,1 | 1,0,1,1,1 |\n| 14 | 1,1,1,0,0 | 1,1,0,1,0 |\n| 15 | 1,1,1,0,1 | 1,1,0,1,1 |\n| 16 | 1,1,1,1,0 | - |\n| 17 | 1,1,1,1,1 | - |\n",
              "createdAt": "2026-02-05T19:19:39Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 592,
              "body": "`ComputeBases` must return an arrayof integer (not scalars) to avoid double conversion.",
              "createdAt": "2026-02-05T19:21:46Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 591,
              "body": "```suggestion\n  # must run in constant-time (branching depends on secret value)\n  for base in bases:\n```",
              "createdAt": "2026-02-05T19:23:32Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 671,
              "body": "we can append a tuple of witness `(b_i,s_i,s2_i)` related to the i-th bit.\n\n```python\nfor i in range(len(b)):\n    vars_b.append(prover.AppendScalar(\"b\" + str(i), b[i]))\n    vars_s.append(prover.AppendScalar(\"s\" + str(i), s[i]))\n    vars_s2.append(prover.AppendScalar(\"s2\" + str(i), s2[i]))\n```\n",
              "createdAt": "2026-02-05T19:26:11Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 760,
              "body": "```suggestion\nThe presentation elements `[tag, nonceCommit, presentationContext, presentationProof, rangeProof]` are indistinguishable from all presentations made from credentials issued with the same server keys for that presentationContext. The nonce is never revealed to the server since it is hidden within a Pedersen commitment. The range proof ensures the committed nonce is within the valid range [0, presentationLimit) without revealing its value. This provides strong unlinkability properties: the server cannot link presentations based on nonce values, as the nonce commitment uses a fresh random blinding factor for each presentation.\n```",
              "createdAt": "2026-02-05T19:29:13Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            },
            {
              "originalPosition": 763,
              "body": "```suggestion\nThe indistinguishability set for these presentation elements is `sum_{i=0}^c(p_i[presentationContext])`, where `c` is the number of credentials issued with the same server keys and `p_i[presentationContext]` is the number of presentations made for each of those credentials with the same presentationContext. Unlike protocols where nonces are revealed, presentations can not be linked by comparing nonce values, resulting in maximum unlinkability within the presentation context.\n```",
              "createdAt": "2026-02-05T19:31:16Z",
              "updatedAt": "2026-02-05T19:32:22Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7gzTLE",
          "commit": {
            "abbreviatedOid": "ac02dfa"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2026-02-09T07:07:40Z",
          "updatedAt": "2026-02-09T07:07:40Z",
          "comments": [
            {
              "originalPosition": 93,
              "body": "Good idea, updated that in the spec and poc.",
              "createdAt": "2026-02-09T07:07:40Z",
              "updatedAt": "2026-02-09T07:07:40Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7gzW5a",
          "commit": {
            "abbreviatedOid": "ac02dfa"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2026-02-09T07:13:15Z",
          "updatedAt": "2026-02-09T07:13:15Z",
          "comments": [
            {
              "originalPosition": 671,
              "body": "I think we can also add `vars_D` to this tuple (appending the element). Updated this, good catch!",
              "createdAt": "2026-02-09T07:13:15Z",
              "updatedAt": "2026-02-09T07:13:15Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7gzlbh",
          "commit": {
            "abbreviatedOid": "ac02dfa"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2026-02-09T07:30:21Z",
          "updatedAt": "2026-02-09T07:30:21Z",
          "comments": [
            {
              "originalPosition": 592,
              "body": "Updated, thanks!",
              "createdAt": "2026-02-09T07:30:21Z",
              "updatedAt": "2026-02-09T07:30:21Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7gzsqi",
          "commit": {
            "abbreviatedOid": "ac02dfa"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2026-02-09T07:39:22Z",
          "updatedAt": "2026-02-09T07:39:22Z",
          "comments": [
            {
              "originalPosition": 458,
              "body": "Added the equation for computing `s2`!",
              "createdAt": "2026-02-09T07:39:22Z",
              "updatedAt": "2026-02-09T07:39:22Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7g0NRq",
          "commit": {
            "abbreviatedOid": "ac02dfa"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2026-02-09T08:09:35Z",
          "updatedAt": "2026-02-09T08:09:35Z",
          "comments": [
            {
              "originalPosition": 142,
              "body": "Agreed, I defined this as `k` and added an explanation in the text.",
              "createdAt": "2026-02-09T08:09:35Z",
              "updatedAt": "2026-02-09T08:09:35Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7g0XOa",
          "commit": {
            "abbreviatedOid": "ac02dfa"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2026-02-09T08:19:09Z",
          "updatedAt": "2026-02-09T08:19:09Z",
          "comments": [
            {
              "originalPosition": 519,
              "body": "That's a good question - for consistency, it would be preferable for all spec-compliant implementations to use the canonical ordering that we define in ComputeBases.\r\n\r\nHowever, if they use an alternative representation, the range proof is still a valid range proof, and would verify correctly (since the verifier has no way to know if they used the canonical or alternative representation; all it can check is that the constraints were satisfied). So we can't actually force rejection of alternative (but still valid) representations, in the verification process. \r\n\r\nMaybe that's okay though, we can still say that spec-compliant implementations need to follow the canonical representation. I'll add that.",
              "createdAt": "2026-02-09T08:19:09Z",
              "updatedAt": "2026-02-09T08:19:09Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7hVvD8",
          "commit": {
            "abbreviatedOid": "7a6c4cd"
          },
          "author": "armfazh",
          "authorAssociation": "CONTRIBUTOR",
          "state": "APPROVED",
          "body": "minor edits, and ready to merge. ",
          "createdAt": "2026-02-10T17:45:11Z",
          "updatedAt": "2026-02-10T17:59:02Z",
          "comments": [
            {
              "originalPosition": 521,
              "body": "here we can hint that this checking must run after `verifier.Verify` has been completed for the sake of running in constant-time ",
              "createdAt": "2026-02-10T17:45:11Z",
              "updatedAt": "2026-02-10T17:59:02Z"
            },
            {
              "originalPosition": 619,
              "body": " `k-1` in the range argument",
              "createdAt": "2026-02-10T17:51:54Z",
              "updatedAt": "2026-02-10T17:59:02Z"
            },
            {
              "originalPosition": 631,
              "body": "either `must` or `MUST`. not sure which one the is adequate in this case\n\n```suggestion\nNote that by extending the range proof for arbitrary ranges, we are changing the bases used for decomposition and therefore introducing the potential for multiple valid decompositions of a value (the nonce). Implementations compliant with this specification MUST to follow the canonical decomposition defined in {{range-proof-creation}}.\n```",
              "createdAt": "2026-02-10T17:54:15Z",
              "updatedAt": "2026-02-10T17:59:02Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7hf0ni",
          "commit": {
            "abbreviatedOid": "7a6c4cd"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2026-02-11T07:19:13Z",
          "updatedAt": "2026-02-11T07:19:13Z",
          "comments": [
            {
              "originalPosition": 631,
              "body": "I'll go with `MUST` here, as we use that language elsewhere as well (eg constant-time-ness).",
              "createdAt": "2026-02-11T07:19:13Z",
              "updatedAt": "2026-02-11T07:19:14Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7hf4lV",
          "commit": {
            "abbreviatedOid": "7a6c4cd"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2026-02-11T07:24:53Z",
          "updatedAt": "2026-02-11T07:24:54Z",
          "comments": [
            {
              "originalPosition": 521,
              "body": "That's not strictly necessary, because `sumValid` is a computation over public data: the bit decomposition commitments, and the total value commitment. So exiting early if `sumValid` is false doesn't reveal any secret data.\r\n\r\nBut to follow good practice, I will combine the two checks into one.",
              "createdAt": "2026-02-11T07:24:53Z",
              "updatedAt": "2026-02-11T07:24:54Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7jdpnO",
          "commit": {
            "abbreviatedOid": "8fb8899"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Do we have a sense for the cost of this new proof? ",
          "createdAt": "2026-02-17T20:43:47Z",
          "updatedAt": "2026-02-18T17:43:50Z",
          "comments": [
            {
              "originalPosition": 92,
              "body": "```suggestion\n  - presentationProof: ZKProof, a joint proof of correct generation of the presentation and that the committed nonce is in [0, presentationLimit).\n```",
              "createdAt": "2026-02-17T20:43:47Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 92,
              "body": "I don't think this is important to the reader at this point.",
              "createdAt": "2026-02-17T20:44:01Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 137,
              "body": "Are any steps above fallible? If so, should we increment `nonce` before the fallible steps occur, so that nonces aren't reused?",
              "createdAt": "2026-02-17T20:45:05Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 171,
              "body": "```suggestion\nstruct {\n  uint8 D[k][Ne]; // k = ceil(log2(presentationLimit))\n  uint8 challenge[Ns];\n  // Variable length based on presentation variables plus range proof variables\n  uint8 responses[5 + 3 * k][Ns];\n} PresentationProof\n```",
              "createdAt": "2026-02-17T20:46:46Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 177,
              "body": "```suggestion\n`k` is the number of bits it takes to represent the presentationLimit, i.e., `k = ceil(log2(presentationLimit))`\n```",
              "createdAt": "2026-02-17T20:47:00Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 209,
              "body": "```suggestion\n  - presentationProof: ZKProof, a joint proof of correct generation of the presentation and that the committed nonce is in [0, presentationLimit).\n```",
              "createdAt": "2026-02-17T20:47:20Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 370,
              "body": "Does this citation render correctly?",
              "createdAt": "2026-02-17T20:49:13Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 463,
              "body": "Can we make this name more informative? Maybe `bitCommits` or something?",
              "createdAt": "2026-02-17T20:50:16Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 522,
              "body": "Does this need to be in constant time?",
              "createdAt": "2026-02-17T20:50:44Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 549,
              "body": "This feels a little confusing to me. Is this checking that the literal sum of 1s and 0s is equal to `nonce`, or is it checking that the composition of those bits sums to `nonce`? For instance, if `nonce = 13`, we'd commit to bits 0, 2, and 3 (`1101b`), and we'd want to prove that the coefficients of these commitments are actually 1 or 0, and that, if we were to sum `1*2^0 + 1*2^2 + 1*2^3` we'd get 13. It sounds like this is saying \"sum 1, 1, 0, 1\", which would yield 4. ",
              "createdAt": "2026-02-17T20:56:17Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 571,
              "body": "(to answer my own question above -- yes, this is what it means!)",
              "createdAt": "2026-02-17T20:57:15Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 698,
              "body": "If this is the case, can we specify it in constant-time?",
              "createdAt": "2026-02-17T20:59:57Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 622,
              "body": "```suggestion\n  bases.append(remainder - 1) # add non-binary base to close the gap\n```",
              "createdAt": "2026-02-17T21:01:24Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            },
            {
              "originalPosition": 625,
              "body": "Can you explain why this step is needed? I assume it _would_ be in the correct order based on how `bases` is computed.",
              "createdAt": "2026-02-17T21:02:00Z",
              "updatedAt": "2026-02-18T17:43:50Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7kTPU9",
          "commit": {
            "abbreviatedOid": "8fb8899"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2026-02-20T06:30:50Z",
          "updatedAt": "2026-02-20T06:30:51Z",
          "comments": [
            {
              "originalPosition": 549,
              "body": "Ah I see what you mean, it's confusing because I say \"the sum of the bits\". \r\nI updated this to say \"the sum of the bits multiplied by their associated bases\" to make it more explicit that it's a linear combination.",
              "createdAt": "2026-02-20T06:30:51Z",
              "updatedAt": "2026-02-20T06:30:51Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7kT7e3",
          "commit": {
            "abbreviatedOid": "8fb8899"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2026-02-20T07:23:23Z",
          "updatedAt": "2026-02-20T07:23:23Z",
          "comments": [
            {
              "originalPosition": 137,
              "body": "The steps above can be fallible, especially the creation of the presentation proof.\r\nHowever if they fail, the presentation wouldn't be successfully created and wouldn't be returned, so we wouldn't have nonce reuse IIUC. But we can be safe and increment the nonce in the very beginning, just to be sure (I made this change in the spec and poc).",
              "createdAt": "2026-02-20T07:23:23Z",
              "updatedAt": "2026-02-20T07:23:23Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7kUKP9",
          "commit": {
            "abbreviatedOid": "8fb8899"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2026-02-20T07:39:39Z",
          "updatedAt": "2026-02-20T07:39:39Z",
          "comments": [
            {
              "originalPosition": 625,
              "body": "This step isn't strictly necessary - we just have to decide on *one* correct ordering of bases and stick to it.\r\n\r\nBut it's not a no-op - without this sorting step, the non-power-of-two base would be at the end. For instance if we were decomposing 10, we would get: `[1, 2, 4, 3]` where `3` is the non-power-of-two base appended to the end.\r\n\r\nBut with this sorting step, we are re-ordering it so `3` gets slotted into the ordered list, as `[1, 2, 3, 4]`. And then we're reversing it, so we actually have `[4, 3, 2, 1]`. Any of these orderings would be fine, we just have to agree on one canonical way to do it.",
              "createdAt": "2026-02-20T07:39:39Z",
              "updatedAt": "2026-02-20T07:39:51Z"
            }
          ]
        },
        {
          "id": "PRR_kwDONyB6uM7kUToH",
          "commit": {
            "abbreviatedOid": "8fb8899"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2026-02-20T07:51:38Z",
          "updatedAt": "2026-02-20T07:51:38Z",
          "comments": [
            {
              "originalPosition": 698,
              "body": "Ah good catch, updated!",
              "createdAt": "2026-02-20T07:51:38Z",
              "updatedAt": "2026-02-20T07:51:38Z"
            }
          ]
        }
      ]
    },
    {
      "number": 54,
      "id": "PR_kwDONyB6uM7Ai2UK",
      "title": "Update draft names to include \"IETF\", update links",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/54",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This PR fixes:\r\n- Naming errors: I previously named the specs `draft-privacypass-arc-*` but left out the `ietf`. This updates all the names to be `draft-ietf-privacypass-arc-*` instead.\r\n- Also updates the links to point to the right place, once the names and tags are updated.\r\n\r\nFollow-up work:\r\n1. After this PR is merged, tag it with `draft-ietf-privacypass-arc-crypto-00`\r\n2. Then, open another PR to update the Datatracker ID reference in `-protocol` to point to that new tag for the `-crypto` spec. (I can't do that in this PR, because the tag does not yet exist)\r\n3. Merge that PR, then tag it with `draft-ietf-privacypass-arc-protocol-00`\r\n4. Also, get Armando added as a code owner (maybe need to add him to the `ietf-wg-privacypass` group?) and add him to the CODEOWNERS file.\r\n5. Delete the incorrect tags from the `draft-arc` repo :)",
      "createdAt": "2026-01-31T08:08:31Z",
      "updatedAt": "2026-02-02T16:19:15Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "565b8f63f17b8889fb169b1e9536b062059dec99",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "rename-ietf",
      "headRefOid": "c4ddfa35ca2e29e499a107676ec4e4428461a1ae",
      "closedAt": "2026-02-02T16:19:14Z",
      "mergedAt": "2026-02-02T16:19:14Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "940715dfd721b070cadc7bd6bccd9fc1d0874c0e"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7e850c",
          "commit": {
            "abbreviatedOid": "c4ddfa3"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2026-02-02T16:19:09Z",
          "updatedAt": "2026-02-02T16:19:09Z",
          "comments": []
        }
      ]
    },
    {
      "number": 55,
      "id": "PR_kwDONyB6uM7BQM1r",
      "title": "Update the crypto spec datatracker ID",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/55",
      "state": "MERGED",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "cathieyun"
      ],
      "labels": [],
      "body": "Now that we have the [draft-ietf-privacypass-arc-crypto-00](https://github.com/ietf-wg-privacypass/draft-arc/releases/tag/draft-ietf-privacypass-arc-crypto-00) tag and the corresponding Datatracker ID (https://datatracker.ietf.org/doc/draft-ietf-privacypass-arc-crypto/), we can update the `draft-ietf-privacypass-arc-protocol` spec to point to the `draft-ietf-privacypass-arc-crypto` Datatracker ID.\r\n\r\n(We couldn't do this earlier, because pointing to  `draft-ietf-privacypass-arc-crypto` before it existed as a Datatracker ID resulted in broken links and therefore broken builds for the editor's copy).",
      "createdAt": "2026-02-03T17:42:22Z",
      "updatedAt": "2026-02-05T20:02:27Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "940715dfd721b070cadc7bd6bccd9fc1d0874c0e",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "update-crypto-spec-id",
      "headRefOid": "d0cf7d5ba9bd47dafede960e35c424d4b2ab706f",
      "closedAt": "2026-02-05T20:02:27Z",
      "mergedAt": "2026-02-05T20:02:27Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "b55ea750ebe443503f6a2916444e37940239f5af"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7gDhmv",
          "commit": {
            "abbreviatedOid": "d0cf7d5"
          },
          "author": "armfazh",
          "authorAssociation": "CONTRIBUTOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2026-02-05T19:33:28Z",
          "updatedAt": "2026-02-05T19:33:28Z",
          "comments": []
        }
      ]
    },
    {
      "number": 63,
      "id": "PR_kwDONyB6uM7G4N-x",
      "title": "Move sage code to use sigma/fiat-shamir code",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/63",
      "state": "OPEN",
      "author": "cathieyun",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Migration of proof-of-concept (sage code) dependencies.\r\nThis is a continuation of the spec migration in this PR: https://github.com/ietf-wg-privacypass/draft-arc/pull/37\r\n\r\nTasks:\r\n\r\n- [x] Add the sigma spec repo as a git submodule: https://github.com/mmaker/draft-irtf-cfrg-sigma-protocols\r\n   - Note: we could add just the `poc` folder as a sparse subtree, but currently we're just adding the whole repository - specs and all. This is nice because we can also reference the spec for the corresponding API, I think?\r\n- [x] Remove poc code related to ZKPs and curves / groups, which is now redundant with the sigma spec poc proof and curve / group code\r\n- [x] Update imports so that the ARC proofs can access the new files\r\n- [x] Update the ARC proofs to use the new files, update call sites.\r\n- [x] Implement seeded PRNG for test vector generation, update tests to use sigma/f-s.\r\n- [ ] Fix some misc building / import bugs",
      "createdAt": "2026-02-27T17:22:35Z",
      "updatedAt": "2026-02-28T18:57:45Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "main",
      "baseRefOid": "167685551557c20eb45b792d168b810bd2fb475b",
      "headRepository": "ietf-wg-privacypass/draft-arc",
      "headRefName": "sigma-poc",
      "headRefOid": "625bdaf7a166ea6f2c907ad9ca1d85d0cf093486",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": []
    },
    {
      "number": 64,
      "id": "PR_kwDONyB6uM7G-XVf",
      "title": "Explicit scalar multiplication instead of operand.",
      "url": "https://github.com/ietf-wg-privacypass/draft-arc/pull/64",
      "state": "MERGED",
      "author": "armfazh",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Group library needs explicti calls to scalar_mult",
      "createdAt": "2026-02-28T05:31:27Z",
      "updatedAt": "2026-02-28T18:57:44Z",
      "baseRepository": "ietf-wg-privacypass/draft-arc",
      "baseRefName": "sigma-poc",
      "baseRefOid": "6c63f99de70bae08964d2f59315c250fe1ff11be",
      "headRepository": "armfazh/draft-arc",
      "headRefName": "scalar_mult",
      "headRefOid": "10fca15c1bd36422f1a25fce143952eb2f37ea79",
      "closedAt": "2026-02-28T18:57:44Z",
      "mergedAt": "2026-02-28T18:57:44Z",
      "mergedBy": "cathieyun",
      "mergeCommit": {
        "oid": "625bdaf7a166ea6f2c907ad9ca1d85d0cf093486"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDONyB6uM7mte7w",
          "commit": {
            "abbreviatedOid": "10fca15"
          },
          "author": "cathieyun",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Thanks for finding the fix, LGTM",
          "createdAt": "2026-02-28T18:57:29Z",
          "updatedAt": "2026-02-28T18:57:29Z",
          "comments": []
        }
      ]
    }
  ]
}